{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoIz6v+OXfw22s4oz7b3Pq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Deep-learning_Theory/blob/main/9-2%20%EC%88%9C%ED%99%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9C%BC%EB%A1%9C%20IMDB%20%EB%A6%AC%EB%B7%B0%20%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저자의 깃허브에서 가져온 코드입니다.\n",
        "# 실행마다 동일한 결과를 얻기 위해 케라스에 랜덤 시드를 사용하고 텐서플로 연산을 결정적으로 만듭니다.\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "tf.config.experimental.enable_op_determinism()"
      ],
      "metadata": {
        "id": "iznSA_M8UtZs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9-2 순환 신경망으로 IMDB 리뷰 분류하기**"
      ],
      "metadata": {
        "id": "IHa2jFvgxB3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDB 리뷰 데이터 세트로 간단한 순환 신경망 모델을 훈련해 보겠습니다. 이 데이터 세트를 두 가지 방법(원-핫 인코딩, 단어 임베딩)으로 변형하여 순환 신경망에 주입해 보겠습니다."
      ],
      "metadata": {
        "id": "BQfRvnA47QMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **IMDB 리뷰 데이터셋**"
      ],
      "metadata": {
        "id": "JVAwuHLmxB0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDB 리뷰 데이터 세트는 인터넷 영화 데이터베이스인 imdb.com 사이트에서 수집한 리뷰를 긍정과 부정으로 분류한 데이터 세트입니다. 샘플 50,000개로 구성되며 훈련 데이터와 테스트 데이터는 25,000개씩 구성됩니다.\n",
        "\n",
        "**자연어 처리(natural language processing, NLP)**는 컴퓨터를 사용하여 인간의 언어(자연어)를 처리하는 분야입니다. 대표되는 세부 분야는 음성 인식, 기계 번역, 감성 분석 등입니다. 이 챕터에서 다룰 데이터 세트로는 감성 분석을 수행합니다. 자연어 처리 분야에서는 훈련 데이터를 **말뭉치(corpus)**라고 부르기도 합니다.\n",
        "\n",
        "기실 텍스트 자체를 신경망에 전달하는 것이 아닙니다. 컴퓨터는 숫자 데이터만 처리할 수 있습니다. 합성곱 신경망에서 이미지를 다룰 때 이미지는 이미 픽셀값(정수)으로 구성되므로 숫자로 변환하는 작업이 필요하지 않습니다. 그러나 텍스트 데이터는 단어를 정수 데이터로 변환하는 작업이 필요합니다. 아래와 같은 문장이 있다고 가정하겠습니다.\n",
        "\n",
        "He follows the cat. He loves the cat.\n",
        "\n",
        "이 문장의 단어인 He, follows, the, cat. 등에 고유한 정수를 부여(매핑)합니다. 같은 단어에는 같은 정수를 부여합니다. 정수 사이에는 어떠한 관계도 없이 고유할 뿐입니다. 일반적으로 영어 문장은 모두 소문자로 바꾸고 구둣점을 삭제하여 공백 기준으로 분리합니다. 이렇게 분리된 단어를 **토큰(token)**이라고 부릅니다. 샘플 하나는 여러 토큰으로 구성되며, 토큰 1개는 타임스텝 하나입니다. 간단한 문제라면 영어 말뭉치에서 토큰을 단어와 같다고 볼 수 있습니다. 토큰에 할당하는 정수 중에 몇 개는 특정 용도로 예약되어 있습니다. 예컨대 0은 패딩, 1은 문장 시작, 2는 어휘 사전(훈련 데이터 세트에서 고유한 단어를 뽑아 생성한 목록)에 존재하지 않는 토큰을 의미합니다. 테스트 데이터 세트에 어휘 사전에 존재하지 않는 단어가 있다면 2로 변환하여 신경망 모델에 주입합니다. \n",
        "\n",
        "참고로 한국어는 영어와 전혀 다릅니다. 한국어는 조사가 발달된 언어이므로 공백으로만 나눠서는 문장 의미를 제대로 분석하기 어렵습니다. 한국어에 대한 자연어 처리는 `KoNLPy`를 사용합니다.\n",
        "\n",
        "IMDB 리뷰 데이터 세트는 영어로 된 문장입니다. 텐서플로에 이 데이터 세트를 정수로 바꾼 데이터가 포함되어 있으므로 굳이 정수로 바꾸는 작업은 필요하지 않습니다. 데이터를 준비하겠습니다."
      ],
      "metadata": {
        "id": "Acowm7Fi76O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# 가장 자주 등장하는 단어 500개만 사용하기 위해 `num_words=500`으로 지정합니다.\n",
        "(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=500)\n",
        "print(train_input.shape, test_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhL8jvLIPvD5",
        "outputId": "d4c8a619-c38a-41fa-9d68-e61a26a9a3a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "(25000,) (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "처음 데이터만 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "NT7IrPdFXy5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWR880R8XgBV",
        "outputId": "2aa29a6c-ec81-4bbe-deb8-2698c64fc496"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list([1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32])\n",
            " list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 2, 8, 118, 2, 14, 394, 20, 13, 119, 2, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 2, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 2, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 2, 7, 2, 2, 349, 2, 148, 2, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 2, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 2, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
            " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 2, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 2, 2, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 2, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 2, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 2, 116, 2, 2, 13, 191, 79, 2, 89, 2, 14, 9, 8, 106, 2, 2, 35, 2, 6, 227, 7, 129, 113])\n",
            " ...\n",
            " list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 2, 84, 2, 325, 2, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 2, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 2, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 2, 108, 45, 40, 29, 2, 395, 11, 6, 2, 2, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 2, 443, 2, 5, 27, 2, 117, 2, 2, 165, 47, 84, 37, 131, 2, 14, 2, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 2, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 2, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 2, 2, 372, 2, 2, 2, 2, 7, 4, 59, 2, 4, 2, 2])\n",
            " list([1, 2, 2, 69, 72, 2, 13, 2, 2, 8, 12, 2, 23, 5, 16, 484, 2, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 2, 32, 61, 369, 71, 66, 2, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 2, 75, 2, 44, 257, 390, 5, 69, 263, 2, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 2, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 2, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 2, 25, 8, 2, 12, 145, 5, 202, 12, 160, 2, 202, 12, 6, 52, 58, 2, 92, 401, 2, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23])\n",
            " list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 2, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 2, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 2, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 2, 5, 383, 2, 2, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 2, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰 텍스트는 길이가 모두 다르므로 2차원 배열에 담지 않고 리뷰마다 별도로 파이썬 리스트로 담아야 메모리를 효율적으로 사용할 수 있습니다. 따라서 리스트 안에 리스트(리뷰 하나) 객체가 여러 개 나열된 형태이며 1차원 넘파이 배열입니다.\n",
        "\n",
        "리뷰 몇 개만 길이를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "z-hgstOTQlaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_input[0]))\n",
        "print(len(train_input[1]))\n",
        "print(len(train_input[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHWBHfZGcFJ0",
        "outputId": "bfd523e9-4f13-4e9a-8639-93530fed3102"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218\n",
            "189\n",
            "141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각각 토큰 218개, 189개, 141개로 구성된 리뷰입니다. 리뷰 하나는 샘플 하나입니다.\n",
        "\n",
        "첫 번째 리뷰 내용만 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "di11waZqcKTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQundAgUctG5",
        "outputId": "e9dc5fcd-212c-468b-9f6c-d9149fdc54a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정수로 변환된 리뷰입니다. 위에서 `num_words=500`으로 지정했으므로 어휘 사전에는 단어가 500개만 구성된 상태이며, 어휘 사전에 없는 단어는 2로 대체됐습니다.\n",
        "\n",
        "타깃 데이터를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "sjAc7q3QcxXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_target[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1meDpNGldRbb",
        "outputId": "37ca8497-c5fb-4d50-f9e4-91a2c3ac32fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "부정은 0, 긍정은 1이며 이진 분류 문제입니다.\n",
        "\n",
        "훈련 데이터 세트에서 검증 데이터 세트를 만들겠습니다."
      ],
      "metadata": {
        "id": "Ls2RYM87dV3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, val_input, train_target, val_target = train_test_split(\n",
        "    train_input, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uRbalZhJdsYB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰의 평균 길이와 중간 길이, 최소 및 최대 길이를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "doR8gnSFeYMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "lengths = np.array([len(x) for x in train_input])\n",
        "# 평균 및 중간값을 구합니다.\n",
        "print(np.mean(lengths), np.median(lengths))\n",
        "# 최솟값 및 최댓값을 구합니다.\n",
        "print(min(lengths), max(lengths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-TwfXDsenr9",
        "outputId": "140b32cf-fb72-43b9-a8a2-7bfdf253a850"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239.00925 178.0\n",
            "11 1854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰 길이 개수를 히스토그램으로 시각화해 보겠습니다."
      ],
      "metadata": {
        "id": "0zwKOPQIflIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(lengths)\n",
        "plt.xlabel('lengths')\n",
        "plt.ylabel('frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "S19eldZLfstB",
        "outputId": "d3f9c425-9e81-47b0-c52d-6640551e1f59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰 대부분은 300미만의 길이를 가집니다. 평균이 중간값보다 높은 이유는 최댓값이 매우 크기 때문입니다.\n",
        "\n",
        "리뷰 대부분 길이가 짧으므로 단어를 100개만 사용하겠습니다. 그러나 단어가 100개 미만으로 구성된 리뷰도 있으므로 리뷰 길이를 100에 맞추기 위해 패딩을 수행해야 합니다. 위에서 서술했듯이 패딩을 나타내는 토큰은 0을 사용합니다.\n",
        "\n",
        "물론 수동으로 훈련 데이터 세트에 있는 리뷰 20,000개를 순회하면서 길이가 100이 되도록 자르거나 0으로 패딩 할 수 있지만 `pad_sequences()` 메서드를 사용하면 시퀀스 데이터 길이를 맞출 수 있습니다. `train_input`의 길이를 100으로 맞춰 보겠습니다."
      ],
      "metadata": {
        "id": "XyxavF1ykiPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# `maxlen` 매개변수에 100을 지정하면 100보다 긴 경우는 잘라내고 짧은 경우는 0으로 패딩합니다.\n",
        "# 아무것도 지정하지 않으면 가장 긴 시퀀스의 길이가 지정됩니다.\n",
        "train_seq = pad_sequences(train_input, maxlen=100)\n",
        "print(train_seq)\n",
        "print(train_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjeyTiHmblJn",
        "outputId": "e516b86b-b03f-42db-e48f-40039fcf03a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 10   4  20 ...  10 470 158]\n",
            " [206   2  26 ...   6   2   2]\n",
            " [  2   7   2 ...   2   2  12]\n",
            " ...\n",
            " [  2  37 299 ...   7  14   2]\n",
            " [  0   0   0 ...  25 170   2]\n",
            " [  0   0   0 ...  25 194   2]]\n",
            "(20000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`train_input`은 리스트 내에 리스트 객체가 구성된 1차원 배열 (20000,)이지만, `train_seq`는 리스트 내에 리스트가 구성된 2차원 배열 (20000, 100)입니다. 샘플 20,000개, 토큰(타임스텝) 개수 100개입니다.\n",
        "\n",
        "첫 번째 샘플만 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "aM9cg43ZfK9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUbKoIpkf3FL",
        "outputId": "5ecf8f1e-8dfd-4c61-d6f0-e4f0437bc6bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2\n",
            "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
            "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
            "   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91\n",
            "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
            "   6   2  46   7  14  20  10  10 470 158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 샘플 길이는 100보다 길었기 때문에 샘플 원소로 0이 없습니다. \n",
        "\n",
        "원본과 비교하여 앞과 뒤 중에 어떤 부분이 잘렸는지 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "KprGcmpaf8l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 맨 앞 원소를 10개만 확인합니다.\n",
        "print(train_input[0][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_nhl4CZhUdH",
        "outputId": "562f8845-714c-4c16-e556-f85c693945dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 73, 89, 81, 25, 60, 2, 6, 20, 141]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 맨 뒤 원소를 10개만 확인합니다.\n",
        "print(train_input[0][-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moy_38A9gcgj",
        "outputId": "00b7655e-d688-4a14-ae14-79da1f4e7712"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 2, 46, 7, 14, 20, 10, 10, 470, 158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`train_input[0]`과 `train_seq[0]`의 앞부분 원소는 불일치하지만 뒷부분 원소는 일치합니다. 앞부분이 잘렸다고 판단할 수 있습니다. 즉 `pad_sequences()` 메서드는 매개변수 `maxlen`에 지정한 값보다 긴 시퀀스의 앞부분을 자릅니다. 앞부분을 자르는 이유는 시퀀스의 뒷부분이 가진 정보가 더 유용할 것이라고 예상하기 때문입니다. 특히 이 리뷰 데이터 세트의 경우 리뷰의 앞부분보다는 뒷부분에 더 결정적이고 중요한 소감을 말할 가능성이 높습니다. 만약 뒷부분을 자르려면 매개변수 `truncating`의 디폴트인 `pre`가 아닌 `post`를 지정합니다.\n",
        "\n",
        "이번에는 `train_seq`의 여섯 번째 샘플을 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "-YM5z0nQhFrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd5IDYyGVTNW",
        "outputId": "fbc87f6d-a458-47e8-f16a-f44004c08b0b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   1   2 195  19  49   2   2 190   4   2 352   2 183  10\n",
            "  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2\n",
            "   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2\n",
            "   2  95  14 238  56 129   2  10  10  21   2  94 364 352   2   2  11 190\n",
            "  24 484   2   7  94 205 405  10  10  87   2  34  49   2   7   2   2   2\n",
            "   2   2 290   2  46  48  64  18   4   2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞부분 원소 4개가 0입니다. 여섯 번째 샘플 길이는 96입니다. 시퀀스의 앞부분을 자르는 것과 같은 이치로써 패딩 토큰 또한 시퀀스의 뒷부분이 아닌 앞부분에 추가됩니다. 시퀀스의 마지막에 구성된 단어가 셀의 은닉 상태에 가장 큰 영향을 미칠 가능성이 높으므로 뒷부분에 패딩을 추가하는 것은 선호되는 방법이 아닙니다. 만약 패딩을 뒷부분에 추가하려면 매개변수 `padding`의 디폴트인 `pre`를 `post`로 지정합니다.\n",
        "\n",
        "검증 데이터 세트의 길이도 100으로 지정하겠습니다."
      ],
      "metadata": {
        "id": "7zBdbdMnYyEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_seq = pad_sequences(val_input, maxlen=100)\n",
        "print(val_seq)\n",
        "print(val_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS2p_k2DaPWU",
        "outputId": "c0bc1cdb-fad8-4b71-da88-2baf99fb1290"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 32   2 225 ...  14  58   2]\n",
            " [ 53   2   8 ...   7  32   2]\n",
            " [  0   0   0 ...   2  33  32]\n",
            " ...\n",
            " [383   2 120 ...  16  99  76]\n",
            " [106 345  12 ... 120   2 156]\n",
            " [  4 114  21 ...   4   2   2]]\n",
            "(5000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **순환 신경망 만들기**"
      ],
      "metadata": {
        "id": "IT8V0OyFxBxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스가 제공하는 여러 순환층 클래스 중 가장 간단하고 기본적인 클래스는 `SimpleRNN`입니다. 이 클래스는 챕터 7의 파트 1에서 설명한 것과 유사한 기능을 가집니다. IMDB 리뷰 분류 문제는 이진 분류 문제입니다. 따라서 마지막 출력층은 유닛 1개를 가지고 시그모이드 활성화 함수를 사용해야 합니다. 먼저 `Sequential` 클래스로 생성한 코드를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "Pk1Ujt-FcuY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.Sequential()\n",
        "# 첫 번째 매개변수는 유닛 개수입니다.\n",
        "model.add(keras.layers.SimpleRNN(8, input_shape=(100, 500)))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "SXOXbAqWdQQi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금까지 살펴왔던 코드와 비슷한 형태입니다. 차이점이라면 `Dense` 클래스나 `Conv2D` 클래스 대신 `SimpleRNN` 클래스를 사용한 것입니다. `SimpleRNN` 클래스의 디폴트 활성화 함수(매개변수 `activation`)는 하이퍼볼릭 탄젠트 함수인 `tanh`이며 다른 함수를 따로 지정하지 않았으므로 디폴트를 그대로 사용합니다. 참고로 `dropout` 매개변수는 입력에 대한 드롭아웃 비율이며, `return_sequences` 매개변수는 모든 타임스텝의 은닉 상태 출력 여부입니다(디폴트 `False`).\n",
        "\n",
        "입력 차원은 (100, 500)입니다. 첫 번째 차원은 샘플 길이가 100이므로 100입니다. 두 번째 차원이 500인 이유는 자세하게 설명할 필요가 있습니다. `train_seq`와 `val_seq`는 문제가 하나 있습니다. 토큰을 정수로 변환한 이 데이터를 신경망에 주입하면 큰 정수가 큰 활성화 출력을 만듭니다. 큰 정수일수록 영향력이 큰 것입니다. 그러나 이 정수 간에는 어떠한 관련성도 없습니다. 예컨대 더 큰 정수인 토큰 20을 더 작은 정수인 토큰 10보다 중요시할 이유가 없습니다. 단순한 정숫값을 신경망에 입력하려면 정숫값의 크기 속성을 없애고 각 정수를 고유하게 표현해야 합니다. 이를 구현할 방법은 원-핫 인코딩입니다. 토큰 10을 원-핫 인코딩으로 바꾸면 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ..., 0이 됩니다. 열한 번째 원소만 1이고 나머지는 0입니다. 이 배열의 길이가 중요합니다. 처음 `imdb.load_data()` 메서드로 데이터를 생성할 때 단어를 500개만 사용하도록 지정했으므로 고유 단어는 500개입니다. 훈련 데이터 세트에 포함될 수 있는 정숫값 범위는 패딩 토큰인 0부터 499까지입니다. 이 범위를 원-핫 인코딩으로 표현하면 배열 길이는 500이 됩니다. 원-핫 인코딩을 수행하는 케라스의 유틸리티는 `keras.utils` 패키지의 `to_categorical()` 메서드입니다. 아래처럼 메서드에 정수 배열을 입력하면 원-핫 인코딩된 배열을 생성합니다."
      ],
      "metadata": {
        "id": "2QXpL1cll36j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_oh = keras.utils.to_categorical(train_seq)\n",
        "print(train_oh)\n",
        "print(train_oh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0rhFqDXR8FL",
        "outputId": "c0b4c63a-f15f-46b7-8b08-b195181d7782"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]]]\n",
            "(20000, 100, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정수마다 500차원 배열로 바뀌었으므로 (20000, 100, 500) 크기가 됐습니다. 이처럼 샘플 데이터 크기가 1차원 정수 배열 (100, )에서 2차원 배열(100, 500)으로 바뀌면서 입력값인 `input_shape`를 (100, 500)으로 지정했습니다.\n",
        "\n",
        "`train_oh`의 첫 번째 샘플의 첫 번째 토큰 10이 어떻게 인코딩됐는지 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "pmp73jKmSK3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 샘플의 첫 번째 토큰 10을 확인합니다.\n",
        "print(train_seq[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKX-hSsXU0w6",
        "outputId": "583f7cf3-22c5-4d24-cede-02a7ae247f4e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2\n",
            "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
            "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
            "   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91\n",
            "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
            "   6   2  46   7  14  20  10  10 470 158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 샘플의 첫 번째 토큰10이 원-핫 인코딩된 결과를 확인합니다.\n",
        "print(train_oh[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oN3Ti13T70t",
        "outputId": "55be4485-4aae-4ea3-dc99-e66fc8cc3396"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "열한 번째만 1이고 나머지는 0입니다. 본서에서는 `print(train_oh[0][0][:12])`로 앞부분 원소만 출력했으나 여기서는 전체를 출력해 봤습니다.\n",
        "\n",
        "아래처럼 모든 원소를 더하면 당연히 1이 됩니다. 원소 하나만 1이기 때문입니다."
      ],
      "metadata": {
        "id": "_jVKhT83VK6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(train_oh[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgNQMWrAVjtk",
        "outputId": "18992ca8-355a-42eb-e473-aae40c64ac22"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`val_seq`도 원-핫 인코딩을 수행하겠습니다."
      ],
      "metadata": {
        "id": "-lCeRucZW1Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_oh = keras.utils.to_categorical(val_seq)\n",
        "print(val_oh[0])\n",
        "print(val_oh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_FIqCw1W5Za",
        "outputId": "a1db8a53-f858-4f5b-c17a-d040c9c3e7db"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "(5000, 100, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 데이터 세트를 준비했습니다.\n",
        "\n",
        "모델 구조를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "4__EKWKUWz3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRIYt-_gXLiG",
        "outputId": "836c7128-dad6-4851-9cd9-c5a1fb0bb9cf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 8)                 4072      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,081\n",
            "Trainable params: 4,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`SimpleRNN`에 전달할 샘플 크기는 (100, 500)이지만 이 순환층은 마지막 타임스텝의 은닉 상태만 출력합니다. 따라서 출력 크기가 순환층의 유닛 개수와 동일한 8입니다(위에서 8로 지정했습니다).\n",
        "\n",
        "순환층에 사용된 모델 파라미터 개수를 산출해 보겠습니다. 입력 토큰은 500차원의 원-핫 인코딩 배열이며, 이 배열이 순환층의 유닛 8개와 완전히 연결되므로 가중치 개수는 500 x 8 = 4,000개입니다. 순환층의 은닉 상태는 다시 다음 타임스텝에 사용되기 위해 또 다른 가중치와 곱해집니다. 이 은닉 상태도 순환층의 유닛과 완전히 연결되므로 가중치는 8(은닉 상태 크기) x 8(유닛 개수) = 64개가 됩니다. 유닛마다 절편 하나가 존재하므로 총 파라미터 개수는 4,000 + 64 + 8 = 4,072개입니다."
      ],
      "metadata": {
        "id": "Ix7-4-TrXRKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **순환 신경망 훈련하기**"
      ],
      "metadata": {
        "id": "KhAcqoM6xBvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "순환 신경망은 완전 연결 신경망 및 합성곱 신경망과 모델을 생성하는 방법은 다르지만 훈련하는 방법은 같습니다. 아래 코드로 구현하고 설명을 이어가겠습니다."
      ],
      "metadata": {
        "id": "Ud1IZ_aNvHic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 RMSprop의 학습률 0.001을 사용하지 않기 위해 \n",
        "# 별도로 RMSprop 객체를 생성하여 학습률을 0.0001로 지정합니다.\n",
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5',\n",
        "                                                save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "history = model.fit(train_oh, train_target, epochs=100, batch_size=64, \n",
        "                    validation_data=(val_oh, val_target),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyPyuZeZvpZE",
        "outputId": "d866b77d-559f-4de4-952c-8cb5385b8dd2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "313/313 [==============================] - 24s 71ms/step - loss: 0.6989 - accuracy: 0.5041 - val_loss: 0.6978 - val_accuracy: 0.5038\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.6946 - accuracy: 0.5102 - val_loss: 0.6949 - val_accuracy: 0.5102\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.6920 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5146\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 24s 77ms/step - loss: 0.6901 - accuracy: 0.5302 - val_loss: 0.6916 - val_accuracy: 0.5230\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 28s 91ms/step - loss: 0.6883 - accuracy: 0.5408 - val_loss: 0.6905 - val_accuracy: 0.5270\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 22s 69ms/step - loss: 0.6866 - accuracy: 0.5472 - val_loss: 0.6894 - val_accuracy: 0.5356\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.6845 - accuracy: 0.5563 - val_loss: 0.6880 - val_accuracy: 0.5416\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.6819 - accuracy: 0.5659 - val_loss: 0.6856 - val_accuracy: 0.5482\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 22s 70ms/step - loss: 0.6777 - accuracy: 0.5828 - val_loss: 0.6807 - val_accuracy: 0.5726\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.6614 - accuracy: 0.6260 - val_loss: 0.6585 - val_accuracy: 0.6240\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 25s 80ms/step - loss: 0.6407 - accuracy: 0.6654 - val_loss: 0.6425 - val_accuracy: 0.6584\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 21s 69ms/step - loss: 0.6272 - accuracy: 0.6841 - val_loss: 0.6296 - val_accuracy: 0.6738\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.6144 - accuracy: 0.6962 - val_loss: 0.6196 - val_accuracy: 0.6848\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.6007 - accuracy: 0.7117 - val_loss: 0.6080 - val_accuracy: 0.6944\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 27s 87ms/step - loss: 0.5875 - accuracy: 0.7220 - val_loss: 0.5973 - val_accuracy: 0.7032\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.5760 - accuracy: 0.7312 - val_loss: 0.5866 - val_accuracy: 0.7110\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 22s 70ms/step - loss: 0.5645 - accuracy: 0.7383 - val_loss: 0.5792 - val_accuracy: 0.7126\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.5534 - accuracy: 0.7440 - val_loss: 0.5674 - val_accuracy: 0.7288\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 24s 78ms/step - loss: 0.5437 - accuracy: 0.7491 - val_loss: 0.5588 - val_accuracy: 0.7312\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.5355 - accuracy: 0.7542 - val_loss: 0.5498 - val_accuracy: 0.7374\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.5258 - accuracy: 0.7605 - val_loss: 0.5389 - val_accuracy: 0.7458\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.5185 - accuracy: 0.7616 - val_loss: 0.5342 - val_accuracy: 0.7494\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.5101 - accuracy: 0.7675 - val_loss: 0.5288 - val_accuracy: 0.7506\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.5039 - accuracy: 0.7717 - val_loss: 0.5190 - val_accuracy: 0.7578\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.4966 - accuracy: 0.7736 - val_loss: 0.5239 - val_accuracy: 0.7508\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.4902 - accuracy: 0.7790 - val_loss: 0.5110 - val_accuracy: 0.7606\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 21s 67ms/step - loss: 0.4847 - accuracy: 0.7816 - val_loss: 0.5060 - val_accuracy: 0.7632\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 21s 68ms/step - loss: 0.4810 - accuracy: 0.7834 - val_loss: 0.5034 - val_accuracy: 0.7640\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.4760 - accuracy: 0.7843 - val_loss: 0.5026 - val_accuracy: 0.7616\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.4709 - accuracy: 0.7880 - val_loss: 0.4981 - val_accuracy: 0.7696\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.4660 - accuracy: 0.7921 - val_loss: 0.4972 - val_accuracy: 0.7688\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.4614 - accuracy: 0.7951 - val_loss: 0.4961 - val_accuracy: 0.7620\n",
            "Epoch 33/100\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.4596 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7686\n",
            "Epoch 34/100\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.4556 - accuracy: 0.7976 - val_loss: 0.4944 - val_accuracy: 0.7636\n",
            "Epoch 35/100\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 0.4529 - accuracy: 0.7987 - val_loss: 0.4874 - val_accuracy: 0.7744\n",
            "Epoch 36/100\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.4499 - accuracy: 0.8025 - val_loss: 0.4866 - val_accuracy: 0.7738\n",
            "Epoch 37/100\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.4470 - accuracy: 0.8043 - val_loss: 0.4831 - val_accuracy: 0.7718\n",
            "Epoch 38/100\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 0.4450 - accuracy: 0.8026 - val_loss: 0.4834 - val_accuracy: 0.7698\n",
            "Epoch 39/100\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.4424 - accuracy: 0.8055 - val_loss: 0.4808 - val_accuracy: 0.7744\n",
            "Epoch 40/100\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.4402 - accuracy: 0.8077 - val_loss: 0.4950 - val_accuracy: 0.7710\n",
            "Epoch 41/100\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.4376 - accuracy: 0.8084 - val_loss: 0.4796 - val_accuracy: 0.7786\n",
            "Epoch 42/100\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.4372 - accuracy: 0.8084 - val_loss: 0.4836 - val_accuracy: 0.7768\n",
            "Epoch 43/100\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 0.4348 - accuracy: 0.8098 - val_loss: 0.4785 - val_accuracy: 0.7810\n",
            "Epoch 44/100\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.4332 - accuracy: 0.8099 - val_loss: 0.4743 - val_accuracy: 0.7794\n",
            "Epoch 45/100\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 0.4319 - accuracy: 0.8102 - val_loss: 0.4806 - val_accuracy: 0.7780\n",
            "Epoch 46/100\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.4293 - accuracy: 0.8126 - val_loss: 0.4747 - val_accuracy: 0.7788\n",
            "Epoch 47/100\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.4281 - accuracy: 0.8134 - val_loss: 0.4728 - val_accuracy: 0.7762\n",
            "Epoch 48/100\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 0.4265 - accuracy: 0.8149 - val_loss: 0.4703 - val_accuracy: 0.7812\n",
            "Epoch 49/100\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 0.4252 - accuracy: 0.8146 - val_loss: 0.4699 - val_accuracy: 0.7798\n",
            "Epoch 50/100\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 0.4235 - accuracy: 0.8166 - val_loss: 0.4676 - val_accuracy: 0.7800\n",
            "Epoch 51/100\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.4222 - accuracy: 0.8173 - val_loss: 0.4684 - val_accuracy: 0.7820\n",
            "Epoch 52/100\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 0.4206 - accuracy: 0.8178 - val_loss: 0.4676 - val_accuracy: 0.7808\n",
            "Epoch 53/100\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 0.4196 - accuracy: 0.8173 - val_loss: 0.4766 - val_accuracy: 0.7774\n",
            "Epoch 54/100\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.4184 - accuracy: 0.8191 - val_loss: 0.4654 - val_accuracy: 0.7824\n",
            "Epoch 55/100\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 0.4171 - accuracy: 0.8198 - val_loss: 0.4636 - val_accuracy: 0.7842\n",
            "Epoch 56/100\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 0.4160 - accuracy: 0.8195 - val_loss: 0.4629 - val_accuracy: 0.7856\n",
            "Epoch 57/100\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.4146 - accuracy: 0.8203 - val_loss: 0.4618 - val_accuracy: 0.7860\n",
            "Epoch 58/100\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.4131 - accuracy: 0.8207 - val_loss: 0.4629 - val_accuracy: 0.7852\n",
            "Epoch 59/100\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.4118 - accuracy: 0.8223 - val_loss: 0.4664 - val_accuracy: 0.7838\n",
            "Epoch 60/100\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.4111 - accuracy: 0.8230 - val_loss: 0.4621 - val_accuracy: 0.7864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "60번째 에포크에서 조기 종료 됐습니다. 검증 데이터 세트에 대한 정확도는 약 79%입니다.\n",
        "\n",
        "훈련 손실과 검증 손실을 그래프로 그려 보겠습니다."
      ],
      "metadata": {
        "id": "vRnPmqAi1ITH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "FhavMoI21ayd",
        "outputId": "cb774793-b2b4-43e6-d217-139235f861ac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 손실은 지속적으로 감소하지만 검증 손실은 대략 30번째 에포크에서 감소 정도가 덜하며 점차 손실 차이가 커집니다. 적절한 에포크에서 훈련을 멈췄습니다. \n",
        "\n",
        "한 가지 고려할 점이라면 원-핫 인코딩을 수행한 데이터는 입력 데이터가 커져서 메모리 소모가 많습니다. 데이터 크기를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "ni-9BKYy1vyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq.nbytes, train_oh.nbytes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ban3XeKz2NZi",
        "outputId": "eab5ef7e-9e45-40e3-acbb-593723dbf6cc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8000000 4000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰 1개를 500차원으로 늘렸으므로 500배 정도 커진 셈입니다. 훈련 데이터가 커질수록 압도적인 크기로 커지기 때문에 결코 적절한 방법은 아닙니다. 아래 파트에서 더 나은 단어 표현 방법을 살펴 보겠습니다."
      ],
      "metadata": {
        "id": "5DtTckqU2WgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **단어 임베딩을 사용하기**"
      ],
      "metadata": {
        "id": "iy34IMEZxBtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**단어 임베딩(word embedding)**은 순환 신경망에서 텍스트를 처리할 때 많이 사용하는 방법입니다. 단어 임베딩은 각 단어를 고정된 크기의 실수 벡터로 바꿉니다. 예컨대 'cat'이라는 단어에 단어 임베딩을 수행하여 0.2/0.1/1.3/0.8/0.2/0.4/1.1/0.9/0.2/0.1라는 벡터로 변환합니다. 이 벡터들은 원-핫 인코딩이 수행된 벡터보다 훨씬 유의미한 값이므로 NLP에서 더 좋은 성능을 내는 경우가 많습니다. 단어 임베딩 벡터를 생성하는 층을 추가하려면 `keras.layers` 패키지의 `Embedding` 클래스를 사용합니다. 이 클래스를 다른 층처럼 모델에 추가하면 처음에는 모든 벡터가 랜덤하게 초기화되지만 훈련을 통해 데이터에서 좋은 단어 임베딩을 학습합니다.\n",
        "\n",
        "단어 임베딩은 정수 데이터(정수로 변환된 토큰)를 입력으로 받습니다. 원-핫 인코딩으로 변환된 배열인 `train_oh`가 아닌 `train_seq`를 바로 사용하여 메모리를 적게 사용할 수 있습니다. 원-핫 인코딩의 경우 1차원 배열인 샘플(100, )을 500차원으로 늘려서 2차원 배열(100, 500)을 만든 것처럼 단어 임베딩도 샘플을 2차원 배열로 늘립니다. 다만 단어 임베딩은 500차원보다 (예를 들면)훨씬 작은 20차원(100, 20)으로 늘립니다. 작은 크기로도 단어를 잘 표현할 수 있기 때문입니다.\n",
        "\n",
        "`Embedding` 클래스를 `SimpleRNN` 층 앞에 추가하여 순환 신경망을 생성해 보겠습니다. `Embedding` 클래스의 첫 번째 매개변수는 어휘 사전 크기이고, 두 번째 매개변수는 단어 임베딩 벡터 크기입니다. 세 번째 매개변수(`input_length`)는 입력 시퀀스 길이이며 `train_seq` 길이를 100으로 축소했으므로 `100`을 지정합니다. 이 매개변수는 `Embedding` 층 바로 뒤에 `Flatten` 클래스나 `Dense` 클래스가 있으면 반드시 지정해야 합니다."
      ],
      "metadata": {
        "id": "5nN77Qy5k7sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.Sequential()\n",
        "\n",
        "model2.add(keras.layers.Embedding(500, 16, input_length=100))\n",
        "model2.add(keras.layers.SimpleRNN(8))\n",
        "model2.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks44TDpm4H4M",
        "outputId": "0a7426c0-d0f0-4ae4-aa12-484c40dd624f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 16)           8000      \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 8)                 200       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,209\n",
            "Trainable params: 8,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 모델은 (100, ) 크기의 입력을 받아 (100, 16) 크기의 출력을 만듭니다. 파라미터 개수는 `Embedding` 층은 500(토큰) x 16(임베딩 벡터) = 8000개입니다. `SimpleRNN` 층은 16(임베딩 벡터) x 8(유닛) = 128개와 은닉 상태에 곱해지는 가중치 8 x 8 = 64개, 그리고 절편 8개를 모두 더하여 200개입니다. 밀집층의 가중치 개수는 이전과 같은 9개 입니다.\n",
        "\n",
        "모델을 훈련해 보겠습니다. 과정은 위와 같습니다."
      ],
      "metadata": {
        "id": "ejjGLKh010DK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model2.compile(optimizer=rmsprop, loss='binary_crossentropy', \n",
        "               metrics=['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.h5', \n",
        "                                                save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "history = model2.fit(train_seq, train_target, epochs=100, batch_size=64,\n",
        "                     validation_data=(val_seq, val_target),\n",
        "                     callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJFmoBo-4IjN",
        "outputId": "08764a06-ca0f-49f5-ccc7-308ccfe9975d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "313/313 [==============================] - 9s 24ms/step - loss: 0.6949 - accuracy: 0.5066 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.6914 - accuracy: 0.5254 - val_loss: 0.6914 - val_accuracy: 0.5242\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.6888 - accuracy: 0.5439 - val_loss: 0.6877 - val_accuracy: 0.5494\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.6793 - accuracy: 0.6054 - val_loss: 0.6740 - val_accuracy: 0.6294\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.6614 - accuracy: 0.6690 - val_loss: 0.6552 - val_accuracy: 0.6844\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.6403 - accuracy: 0.7056 - val_loss: 0.6359 - val_accuracy: 0.7028\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6205 - accuracy: 0.7247 - val_loss: 0.6177 - val_accuracy: 0.7180\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.6019 - accuracy: 0.7400 - val_loss: 0.6003 - val_accuracy: 0.7348\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.5855 - accuracy: 0.7519 - val_loss: 0.5938 - val_accuracy: 0.7322\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.5701 - accuracy: 0.7618 - val_loss: 0.5724 - val_accuracy: 0.7590\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.5549 - accuracy: 0.7713 - val_loss: 0.5619 - val_accuracy: 0.7634\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.5412 - accuracy: 0.7785 - val_loss: 0.5497 - val_accuracy: 0.7600\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.5294 - accuracy: 0.7822 - val_loss: 0.5404 - val_accuracy: 0.7682\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.5171 - accuracy: 0.7889 - val_loss: 0.5314 - val_accuracy: 0.7652\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.5062 - accuracy: 0.7914 - val_loss: 0.5235 - val_accuracy: 0.7720\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4954 - accuracy: 0.7975 - val_loss: 0.5142 - val_accuracy: 0.7746\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.4855 - accuracy: 0.8008 - val_loss: 0.5175 - val_accuracy: 0.7646\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4780 - accuracy: 0.8019 - val_loss: 0.5004 - val_accuracy: 0.7794\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4692 - accuracy: 0.8049 - val_loss: 0.4962 - val_accuracy: 0.7778\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 8s 25ms/step - loss: 0.4619 - accuracy: 0.8069 - val_loss: 0.4904 - val_accuracy: 0.7796\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 8s 25ms/step - loss: 0.4561 - accuracy: 0.8087 - val_loss: 0.4865 - val_accuracy: 0.7804\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.4502 - accuracy: 0.8112 - val_loss: 0.4970 - val_accuracy: 0.7690\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4449 - accuracy: 0.8124 - val_loss: 0.4825 - val_accuracy: 0.7802\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4391 - accuracy: 0.8138 - val_loss: 0.4787 - val_accuracy: 0.7832\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.4359 - accuracy: 0.8161 - val_loss: 0.4763 - val_accuracy: 0.7820\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.4306 - accuracy: 0.8191 - val_loss: 0.4780 - val_accuracy: 0.7782\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4277 - accuracy: 0.8193 - val_loss: 0.4745 - val_accuracy: 0.7790\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.4246 - accuracy: 0.8202 - val_loss: 0.4711 - val_accuracy: 0.7810\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.4217 - accuracy: 0.8208 - val_loss: 0.4801 - val_accuracy: 0.7784\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4186 - accuracy: 0.8220 - val_loss: 0.4741 - val_accuracy: 0.7798\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4154 - accuracy: 0.8237 - val_loss: 0.4747 - val_accuracy: 0.7766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원-핫 인코딩과 비슷한 성능이지만 순환층의 가중치 개수는 훨씬 적고 훈련 데이터 세트 크기도 훨씬 작아졌습니다. \n",
        "\n",
        "훈련 손실과 검증 손실을 그래프로 그려 보겠습니다."
      ],
      "metadata": {
        "id": "CgcdRsjBeLch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "qCb9_8wT4Kvk",
        "outputId": "aebcc42a-e766-43a4-f7b9-d82f24b7103a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원-핫 인코딩에 대한 결과와 비슷합니다. 다음 챕터에서 결과를 개선할 방안을 모색해 보겠습니다."
      ],
      "metadata": {
        "id": "YS4EPvYaec9G"
      }
    }
  ]
}