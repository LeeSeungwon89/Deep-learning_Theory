{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXQWfF5kVcZCLsn82mpMll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Deep-learning_Theory/blob/main/9-2%20%EC%88%9C%ED%99%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9C%BC%EB%A1%9C%20IMDB%20%EB%A6%AC%EB%B7%B0%20%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9-2 순환 신경망으로 IMDB 리뷰 분류하기**"
      ],
      "metadata": {
        "id": "IHa2jFvgxB3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDB 리뷰 데이터 세트로 간단한 순환 신경망 모델을 훈련해 보겠습니다. 이 데이터 세트를 두 가지 방법(원-핫 인코딩, 단어 임베딩)으로 변형하여 순환 신경망에 주입해 보겠습니다."
      ],
      "metadata": {
        "id": "BQfRvnA47QMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **IMDB 리뷰 데이터셋**"
      ],
      "metadata": {
        "id": "JVAwuHLmxB0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDB 리뷰 데이터 세트는 인터넷 영화 데이터베이스인 imdb.com 사이트에서 수집한 리뷰를 긍정과 부정으로 분류한 데이터 세트입니다. 샘플 50,000개로 구성되며 훈련 데이터와 테스트 데이터는 25,000개씩 구성됩니다.\n",
        "\n",
        "**자연어 처리(natural language processing, NLP)**는 컴퓨터를 사용하여 인간의 언어(자연어)를 처리하는 분야입니다. 대표되는 세부 분야는 음성 인식, 기계 번역, 감성 분석 등입니다. 이 챕터에서 다룰 데이터 세트로는 감성 분석을 수행합니다. 자연어 처리 분야에서는 훈련 데이터를 **말뭉치(corpus)**라고 부르기도 합니다.\n",
        "\n",
        "기실 텍스트 자체를 신경망에 전달하는 것이 아닙니다. 컴퓨터는 숫자 데이터만 처리할 수 있습니다. 합성곱 신경망에서 이미지를 다룰 때 이미지는 이미 픽셀값(정수)으로 구성되므로 숫자로 변환하는 작업이 필요하지 않습니다. 그러나 텍스트 데이터는 단어를 정수 데이터로 변환하는 작업이 필요합니다. 아래와 같은 문장이 있다고 가정하겠습니다.\n",
        "\n",
        "He follows the cat. He loves the cat.\n",
        "\n",
        "이 문장의 단어인 He, follows, the, cat. 등에 고유한 정수를 부여(매핑)합니다. 같은 단어에는 같은 정수를 부여합니다. 정수 사이에는 어떠한 관계도 없이 고유할 뿐입니다. 일반적으로 영어 문장은 모두 소문자로 바꾸고 구둣점을 삭제하여 공백 기준으로 분리합니다. 이렇게 분리된 단어를 **토큰(token)**이라고 부릅니다. 샘플 하나는 여러 토큰으로 구성되며, 토큰 1개는 타임스템프 하나입니다. 간단한 문제라면 영어 말뭉치에서 토큰을 단어와 같다고 볼 수 있습니다. 토큰에 할당하는 정수 중에 몇 개는 특정 용도로 예약되어 있습니다. 예컨대 0은 패딩, 1은 문장 시작, 2는 어휘 사전(훈련 데이터 세트에서 고유한 단어를 뽑아 생성한 목록)에 존재하지 않는 토큰을 의미합니다. 테스트 데이터 세트에 어휘 사전에 존재하지 않는 단어가 있다면 2로 변환하여 신경망 모델에 주입합니다. \n",
        "\n",
        "참고로 한국어는 영어와 전혀 다릅니다. 한국어는 조사가 발달된 언어이므로 공백으로만 나눠서는 문장 의미를 제대로 분석하기 어렵습니다. 한국어에 대한 자연어 처리는 `KoNLPy`를 사용합니다.\n",
        "\n",
        "IMDB 리뷰 데이터 세트는 영어로 된 문장입니다. 텐서플로에 이 데이터 세트를 정수로 바꾼 데이터가 포함되어 있으므로 굳이 정수로 바꾸는 작업은 필요하지 않습니다. 데이터를 준비하겠습니다."
      ],
      "metadata": {
        "id": "Acowm7Fi76O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# 가장 자주 등장하는 단어 500개만 사용하기 위해 `num_words=500`으로 지정합니다.\n",
        "(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=500)\n",
        "print(train_input.shape, test_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhL8jvLIPvD5",
        "outputId": "afea0dfa-d777-4e5c-a77e-de6b8ebe2331"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "(25000,) (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "처음 데이터만 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "NT7IrPdFXy5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWR880R8XgBV",
        "outputId": "7b110a40-2e79-4e46-c677-fa4cd076dbaf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list([1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32])\n",
            " list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 2, 8, 118, 2, 14, 394, 20, 13, 119, 2, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 2, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 2, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 2, 7, 2, 2, 349, 2, 148, 2, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 2, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 2, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
            " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 2, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 2, 2, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 2, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 2, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 2, 116, 2, 2, 13, 191, 79, 2, 89, 2, 14, 9, 8, 106, 2, 2, 35, 2, 6, 227, 7, 129, 113])\n",
            " ...\n",
            " list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 2, 84, 2, 325, 2, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 2, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 2, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 2, 108, 45, 40, 29, 2, 395, 11, 6, 2, 2, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 2, 443, 2, 5, 27, 2, 117, 2, 2, 165, 47, 84, 37, 131, 2, 14, 2, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 2, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 2, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 2, 2, 372, 2, 2, 2, 2, 7, 4, 59, 2, 4, 2, 2])\n",
            " list([1, 2, 2, 69, 72, 2, 13, 2, 2, 8, 12, 2, 23, 5, 16, 484, 2, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 2, 32, 61, 369, 71, 66, 2, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 2, 75, 2, 44, 257, 390, 5, 69, 263, 2, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 2, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 2, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 2, 25, 8, 2, 12, 145, 5, 202, 12, 160, 2, 202, 12, 6, 52, 58, 2, 92, 401, 2, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23])\n",
            " list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 2, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 2, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 2, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 2, 5, 383, 2, 2, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 2, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰 텍스트는 길이가 모두 다르므로 2차원 배열에 담지 않고 리뷰마다 별도로 파이썬 리스트로 담아야 메모리를 효율적으로 사용할 수 있습니다. 따라서 리스트 안에 리스트(리뷰 하나) 객체가 여러 개 나열된 형태이며 1차원 넘파이 배열입니다.\n",
        "\n",
        "리뷰 몇 개만 길이를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "z-hgstOTQlaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_input[0]))\n",
        "print(len(train_input[1]))\n",
        "print(len(train_input[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHWBHfZGcFJ0",
        "outputId": "2fd21d51-2780-4459-efa3-3b0535a344d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218\n",
            "189\n",
            "141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각각 토큰 218개, 189개, 141개로 구성된 리뷰입니다. 리뷰 하나는 샘플 하나입니다.\n",
        "\n",
        "첫 번째 리뷰 내용만 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "di11waZqcKTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQundAgUctG5",
        "outputId": "124c3132-077c-417a-e16b-a77e7445b767"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정수로 변환된 리뷰입니다. 위에서 `num_words=500`으로 지정했으므로 어휘 사전에는 단어가 500개만 구성된 상태이며, 어휘 사전에 없는 단어는 2로 대체됐습니다.\n",
        "\n",
        "타깃 데이터를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "sjAc7q3QcxXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_target[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1meDpNGldRbb",
        "outputId": "fdb2d059-7e17-46a5-e4cf-87a52a900d62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "부정은 0, 긍정은 1이며 이진 분류 문제입니다.\n",
        "\n",
        "훈련 데이터 세트에서 검증 데이터 세트를 만들겠습니다."
      ],
      "metadata": {
        "id": "Ls2RYM87dV3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, val_input, train_target, val_target = train_test_split(\n",
        "    train_input, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uRbalZhJdsYB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰의 평균 길이와 중간 길이, 최소 및 최대 길이를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "doR8gnSFeYMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "lengths = np.array([len(x) for x in train_input])\n",
        "# 평균 및 중간값을 구합니다.\n",
        "print(np.mean(lengths), np.median(lengths))\n",
        "# 최솟값 및 최댓값을 구합니다.\n",
        "print(min(lengths), max(lengths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-TwfXDsenr9",
        "outputId": "a0cf3843-0b63-4271-fd64-4050ec4f1d92"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239.00925 178.0\n",
            "11 1854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰 길이 개수를 히스토그램으로 시각화해 보겠습니다."
      ],
      "metadata": {
        "id": "0zwKOPQIflIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(lengths)\n",
        "plt.xlabel('lengths')\n",
        "plt.ylabel('frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "S19eldZLfstB",
        "outputId": "b7af55b0-df8b-463d-908f-ade308a53938"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰 대부분은 300미만의 길이를 가집니다. 평균이 중간값보다 높은 이유는 최댓값이 매우 크기 때문입니다.\n",
        "\n",
        "리뷰 대부분 길이가 짧으므로 단어를 100개만 사용하겠습니다. 그러나 단어가 100개 미만으로 구성된 리뷰도 있으므로 리뷰 길이를 100에 맞추기 위해 패딩을 수행해야 합니다. 위에서 서술했듯이 패딩을 나타내는 토큰은 0을 사용합니다.\n",
        "\n",
        "물론 수동으로 훈련 데이터 세트에 있는 리뷰 20,000개를 순회하면서 길이가 100이 되도록 자르거나 0으로 패딩 할 수 있지만 `pad_sequences()` 메서드를 사용하면 시퀀스 데이터 길이를 맞출 수 있습니다. `train_input`의 길이를 100으로 맞춰 보겠습니다."
      ],
      "metadata": {
        "id": "XyxavF1ykiPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# `maxlen` 매개변수에 100으로 지정하면 긴 경우는 잘라내고 짧은 경우는 0으로 패딩합니다.\n",
        "train_seq = pad_sequences(train_input, maxlen=100)\n",
        "print(train_seq)\n",
        "print(train_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjeyTiHmblJn",
        "outputId": "f4045cd2-5bd7-43f9-c667-c1c4ea959c28"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 10   4  20 ...  10 470 158]\n",
            " [206   2  26 ...   6   2   2]\n",
            " [  2   7   2 ...   2   2  12]\n",
            " ...\n",
            " [  2  37 299 ...   7  14   2]\n",
            " [  0   0   0 ...  25 170   2]\n",
            " [  0   0   0 ...  25 194   2]]\n",
            "(20000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`train_input`은 리스트 내에 리스트 객체가 구성된 1차원 배열 (20000,)이지만, `train_seq`는 리스트 내에 리스트가 구성된 2차원 배열 (20000, 100)입니다. 샘플 20,000개, 토큰(타임스텝) 개수 100개입니다.\n",
        "\n",
        "첫 번째 샘플만 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "aM9cg43ZfK9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUbKoIpkf3FL",
        "outputId": "8b50e63e-5d59-47d5-fef2-d8f5f3ab7da5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2\n",
            "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
            "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
            "   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91\n",
            "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
            "   6   2  46   7  14  20  10  10 470 158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 샘플 길이는 100보다 길었기 때문에 샘플 원소로 0이 없습니다. \n",
        "\n",
        "원본과 비교하여 앞과 뒤 중에 어떤 부분이 잘렸는지 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "KprGcmpaf8l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 맨 앞 원소를 10개만 확인합니다.\n",
        "print(train_input[0][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_nhl4CZhUdH",
        "outputId": "f53c54af-f81a-4dcb-c339-0ce37f90a919"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 73, 89, 81, 25, 60, 2, 6, 20, 141]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 맨 뒤 원소를 10개만 확인합니다.\n",
        "print(train_input[0][-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moy_38A9gcgj",
        "outputId": "ba701fe4-a9d1-41bc-c369-392d241a6ab4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 2, 46, 7, 14, 20, 10, 10, 470, 158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`train_input[0]`과 `train_seq[0]`의 앞부분 원소는 불일치하지만 뒷부분 원소는 일치합니다. 앞부분이 잘렸다고 판단할 수 있습니다. 즉 `pad_sequences()` 메서드는 매개변수 `maxlen`에 지정한 값보다 긴 시퀀스의 앞부분을 자릅니다. 앞부분을 자르는 이유는 시퀀스의 뒷부분이 가진 정보가 더 유용할 것이라고 예상하기 때문입니다. 특히 이 리뷰 데이터 세트의 경우 리뷰의 앞부분보다는 뒷부분에 더 결정적이고 중요한 소감을 말할 가능성이 높습니다. 만약 뒷부분을 자르려면 매개변수 `truncating`의 디폴트인 `pre`가 아닌 `post`를 지정합니다.\n",
        "\n",
        "이번에는 `train_seq`의 여섯 번째 샘플을 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "-YM5z0nQhFrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd5IDYyGVTNW",
        "outputId": "dedf96e4-b8a1-4935-cbb8-0c279907de78"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   1   2 195  19  49   2   2 190   4   2 352   2 183  10\n",
            "  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2\n",
            "   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2\n",
            "   2  95  14 238  56 129   2  10  10  21   2  94 364 352   2   2  11 190\n",
            "  24 484   2   7  94 205 405  10  10  87   2  34  49   2   7   2   2   2\n",
            "   2   2 290   2  46  48  64  18   4   2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞부분 원소 4개가 0입니다. 여섯 번째 샘플 길이는 96입니다. 시퀀스의 앞부분을 자르는 것과 같은 이치로써 패딩 토큰 또한 시퀀스의 뒷부분이 아닌 앞부분에 추가됩니다. 시퀀스의 마지막에 구성된 단어가 셀의 은닉 상태에 가장 큰 영향을 미칠 가능성이 높으므로 뒷부분에 패딩을 추가하는 것은 선호되는 방법이 아닙니다. 만약 패딩을 뒷부분에 추가하려면 매개변수 `padding`의 디폴트인 `pre`를 `post`로 지정합니다.\n",
        "\n",
        "검증 데이터 세트의 길이도 100으로 지정하겠습니다."
      ],
      "metadata": {
        "id": "7zBdbdMnYyEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_seq = pad_sequences(val_input, maxlen=100)\n",
        "print(val_seq)\n",
        "print(val_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS2p_k2DaPWU",
        "outputId": "29bb1c1e-4ff4-4726-db15-d2d26c972043"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 32   2 225 ...  14  58   2]\n",
            " [ 53   2   8 ...   7  32   2]\n",
            " [  0   0   0 ...   2  33  32]\n",
            " ...\n",
            " [383   2 120 ...  16  99  76]\n",
            " [106 345  12 ... 120   2 156]\n",
            " [  4 114  21 ...   4   2   2]]\n",
            "(5000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **순환 신경망 만들기**"
      ],
      "metadata": {
        "id": "IT8V0OyFxBxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "작업 중\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "k9zCm_2mOszC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **순환 신경망 훈련하기**"
      ],
      "metadata": {
        "id": "KhAcqoM6xBvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **단어 임베딩을 사용하기**"
      ],
      "metadata": {
        "id": "iy34IMEZxBtK"
      }
    }
  ]
}