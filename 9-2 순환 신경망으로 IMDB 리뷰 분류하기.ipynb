{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcTfpzUbCklSdvx/WnKS2G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Deep-learning_Theory/blob/main/9-2%20%EC%88%9C%ED%99%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9C%BC%EB%A1%9C%20IMDB%20%EB%A6%AC%EB%B7%B0%20%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9-2 순환 신경망으로 IMDB 리뷰 분류하기**"
      ],
      "metadata": {
        "id": "IHa2jFvgxB3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDB 리뷰 데이터 세트로 간단한 순환 신경망 모델을 훈련해 보겠습니다. 이 데이터 세트를 두 가지 방법(원-핫 인코딩, 단어 임베딩)으로 변형하여 순환 신경망에 주입해 보겠습니다."
      ],
      "metadata": {
        "id": "BQfRvnA47QMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **IMDB 리뷰 데이터셋**"
      ],
      "metadata": {
        "id": "JVAwuHLmxB0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDB 리뷰 데이터 세트는 인터넷 영화 데이터베이스인 imdb.com 사이트에서 수집한 리뷰를 긍정과 부정으로 분류한 데이터 세트입니다. 샘플 50,000개로 구성되며 훈련 데이터와 테스트 데이터는 25,000개씩 구성됩니다.\n",
        "\n",
        "**자연어 처리(natural language processing, NLP)**는 컴퓨터를 사용하여 인간의 언어(자연어)를 처리하는 분야입니다. 대표되는 세부 분야는 음성 인식, 기계 번역, 감성 분석 등입니다. 이 챕터에서 다룰 데이터 세트로는 감성 분석을 수행합니다. 자연어 처리 분야에서는 훈련 데이터를 **말뭉치(corpus)**라고 부르기도 합니다.\n",
        "\n",
        "기실 텍스트 자체를 신경망에 전달하는 것이 아닙니다. 컴퓨터는 숫자 데이터만 처리할 수 있습니다. 합성곱 신경망에서 이미지를 다룰 때 이미지는 이미 픽셀값(정수)으로 구성되므로 숫자로 변환하는 작업이 필요하지 않습니다. 그러나 텍스트 데이터는 단어를 정수 데이터로 변환하는 작업이 필요합니다. 아래와 같은 문장이 있다고 가정하겠습니다.\n",
        "\n",
        "He follows the cat. He loves the cat.\n",
        "\n",
        "이 문장의 단어인 He, follows, the, cat. 등에 고유한 정수를 부여(매핑)합니다. 같은 단어에는 같은 정수를 부여합니다. 정수 사이에는 어떠한 관계도 없이 고유할 뿐입니다. 일반적으로 영어 문장은 모두 소문자로 바꾸고 구둣점을 삭제하여 공백 기준으로 분리합니다. 이렇게 분리된 단어를 **토큰(token)**이라고 부릅니다. 샘플 하나는 여러 토큰으로 구성되며, 토큰 1개는 타임스템프 하나입니다. 간단한 문제라면 영어 말뭉치에서 토큰을 단어와 같다고 볼 수 있습니다. 토큰에 할당하는 정수 중에 몇 개는 특정 용도로 예약되어 있습니다. 예컨대 0은 패딩, 1은 문장 시작, 2는 어휘 사전(훈련 데이터 세트에서 고유한 단어를 뽑아 생성한 목록)에 존재하지 않는 토큰을 의미합니다. 테스트 데이터 세트에 어휘 사전에 존재하지 않는 단어가 있다면 2로 변환하여 신경망 모델에 주입합니다. \n",
        "\n",
        "참고로 한국어는 영어와 전혀 다릅니다. 한국어는 조사가 발달된 언어이므로 공백으로만 나눠서는 문장 의미를 제대로 분석하기 어렵습니다. 한국어에 대한 자연어 처리는 `KoNLPy`를 사용합니다.\n",
        "\n",
        "IMDB 리뷰 데이터 세트는 영어로 된 문장입니다. 텐서플로에 이 데이터 세트를 정수로 바꾼 데이터가 포함되어 있으므로 굳이 정수로 바꾸는 작업은 필요하지 않습니다. 데이터를 준비하겠습니다."
      ],
      "metadata": {
        "id": "Acowm7Fi76O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# 가장 자주 등장하는 단어 500개만 사용하기 위해 `num_words=500`으로 지정합니다.\n",
        "(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=500)\n",
        "print(train_input.shape, test_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhL8jvLIPvD5",
        "outputId": "3afdd75e-1047-48ed-b467-bfe5bdeedcc5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "(25000,) (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "처음 데이터만 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "NT7IrPdFXy5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWR880R8XgBV",
        "outputId": "8eaf2736-b0c1-44a1-853f-196238fbb9a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list([1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32])\n",
            " list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 2, 8, 118, 2, 14, 394, 20, 13, 119, 2, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 2, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 2, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 2, 7, 2, 2, 349, 2, 148, 2, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 2, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 2, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
            " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 2, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 2, 2, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 2, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 2, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 2, 116, 2, 2, 13, 191, 79, 2, 89, 2, 14, 9, 8, 106, 2, 2, 35, 2, 6, 227, 7, 129, 113])\n",
            " ...\n",
            " list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 2, 84, 2, 325, 2, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 2, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 2, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 2, 108, 45, 40, 29, 2, 395, 11, 6, 2, 2, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 2, 443, 2, 5, 27, 2, 117, 2, 2, 165, 47, 84, 37, 131, 2, 14, 2, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 2, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 2, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 2, 2, 372, 2, 2, 2, 2, 7, 4, 59, 2, 4, 2, 2])\n",
            " list([1, 2, 2, 69, 72, 2, 13, 2, 2, 8, 12, 2, 23, 5, 16, 484, 2, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 2, 32, 61, 369, 71, 66, 2, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 2, 75, 2, 44, 257, 390, 5, 69, 263, 2, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 2, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 2, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 2, 25, 8, 2, 12, 145, 5, 202, 12, 160, 2, 202, 12, 6, 52, 58, 2, 92, 401, 2, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23])\n",
            " list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 2, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 2, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 2, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 2, 5, 383, 2, 2, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 2, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰 텍스트는 길이가 모두 다르므로 2차원 배열에 담지 않고 리뷰마다 별도로 파이썬 리스트로 담아야 메모리를 효율적으로 사용할 수 있습니다. 따라서 리스트 안에 리스트(리뷰 하나) 객체가 여러 개 나열된 형태이며 1차원 넘파이 배열입니다.\n",
        "\n",
        "리뷰 몇 개만 길이를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "z-hgstOTQlaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_input[0]))\n",
        "print(len(train_input[1]))\n",
        "print(len(train_input[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHWBHfZGcFJ0",
        "outputId": "a5dbee16-fef5-4b70-93fa-9a05a42b84ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218\n",
            "189\n",
            "141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각각 토큰 218개, 189개, 141개로 구성된 리뷰입니다. 리뷰 하나는 샘플 하나입니다.\n",
        "\n",
        "첫 번째 리뷰 내용만 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "di11waZqcKTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQundAgUctG5",
        "outputId": "f61f0944-da57-44bd-e74c-29f5ad76fbf5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정수로 변환된 리뷰입니다. 위에서 `num_words=500`으로 지정했으므로 어휘 사전에는 단어가 500개만 구성된 상태이며, 어휘 사전에 없는 단어는 2로 대체됐습니다.\n",
        "\n",
        "타깃 데이터를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "sjAc7q3QcxXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_target[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1meDpNGldRbb",
        "outputId": "f1653411-0fbb-418e-c384-084943891cae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "부정은 0, 긍정은 1이며 이진 분류 문제입니다.\n",
        "\n",
        "훈련 데이터 세트에서 검증 데이터 세트를 만들겠습니다."
      ],
      "metadata": {
        "id": "Ls2RYM87dV3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, val_input, train_target, val_target = train_test_split(\n",
        "    train_input, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uRbalZhJdsYB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰의 평균 길이와 중간 길이, 최소 및 최대 길이를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "doR8gnSFeYMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "lengths = np.array([len(x) for x in train_input])\n",
        "# 평균 및 중간값을 구합니다.\n",
        "print(np.mean(lengths), np.median(lengths))\n",
        "# 최솟값 및 최댓값을 구합니다.\n",
        "print(min(lengths), max(lengths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-TwfXDsenr9",
        "outputId": "23b0f9e3-4100-46ef-a53d-9e4259f3ce84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239.00925 178.0\n",
            "11 1854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰 길이 개수를 히스토그램으로 시각화해 보겠습니다."
      ],
      "metadata": {
        "id": "0zwKOPQIflIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(lengths)\n",
        "plt.xlabel('lengths')\n",
        "plt.ylabel('frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "S19eldZLfstB",
        "outputId": "36ef66cf-4fae-4296-c67e-ea34bd7509b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰 대부분은 300미만의 길이를 가집니다. 평균이 중간값보다 높은 이유는 최댓값이 매우 크기 때문입니다.\n",
        "\n",
        "리뷰 대부분 길이가 짧으므로 단어를 100개만 사용하겠습니다. 그러나 단어가 100개 미만으로 구성된 리뷰도 있으므로 리뷰 길이를 100에 맞추기 위해 패딩을 수행해야 합니다. 위에서 서술했듯이 패딩을 나타내는 토큰은 0을 사용합니다.\n",
        "\n",
        "물론 수동으로 훈련 데이터 세트에 있는 리뷰 20,000개를 순회하면서 길이가 100이 되도록 자르거나 0으로 패딩 할 수 있지만 `pad_sequences()` 메서드를 사용하면 시퀀스 데이터 길이를 맞출 수 있습니다. `train_input`의 길이를 100으로 맞춰 보겠습니다."
      ],
      "metadata": {
        "id": "XyxavF1ykiPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# `maxlen` 매개변수에 100으로 지정하면 긴 경우는 잘라내고 짧은 경우는 0으로 패딩합니다.\n",
        "train_seq = pad_sequences(train_input, maxlen=100)\n",
        "print(train_seq)\n",
        "print(train_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjeyTiHmblJn",
        "outputId": "909834be-6c12-427f-c20a-0beee90b5885"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 10   4  20 ...  10 470 158]\n",
            " [206   2  26 ...   6   2   2]\n",
            " [  2   7   2 ...   2   2  12]\n",
            " ...\n",
            " [  2  37 299 ...   7  14   2]\n",
            " [  0   0   0 ...  25 170   2]\n",
            " [  0   0   0 ...  25 194   2]]\n",
            "(20000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`train_input`은 리스트 내에 리스트 객체가 구성된 1차원 배열 (20000,)이지만, `train_seq`는 리스트 내에 리스트가 구성된 2차원 배열 (20000, 100)입니다. 샘플 20,000개, 토큰(타임스텝) 개수 100개입니다.\n",
        "\n",
        "첫 번째 샘플만 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "aM9cg43ZfK9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUbKoIpkf3FL",
        "outputId": "fb3ee27d-2916-43de-b04a-0959622e709e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2\n",
            "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
            "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
            "   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91\n",
            "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
            "   6   2  46   7  14  20  10  10 470 158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 샘플 길이는 100보다 길었기 때문에 샘플 원소로 0이 없습니다. \n",
        "\n",
        "원본과 비교하여 앞과 뒤 중에 어떤 부분이 잘렸는지 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "KprGcmpaf8l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 맨 앞 원소를 10개만 확인합니다.\n",
        "print(train_input[0][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_nhl4CZhUdH",
        "outputId": "3da7a7df-fd10-42d2-ec1b-7c2b784c8b74"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 73, 89, 81, 25, 60, 2, 6, 20, 141]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 맨 뒤 원소를 10개만 확인합니다.\n",
        "print(train_input[0][-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moy_38A9gcgj",
        "outputId": "58911e43-c11d-4163-c56f-fa5b84548ef0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 2, 46, 7, 14, 20, 10, 10, 470, 158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`train_input[0]`과 `train_seq[0]`의 앞부분 원소는 불일치하지만 뒷부분 원소는 일치합니다. 앞부분이 잘렸다고 판단할 수 있습니다. 즉 `pad_sequences()` 메서드는 매개변수 `maxlen`에 지정한 값보다 긴 시퀀스의 앞부분을 자릅니다. 앞부분을 자르는 이유는 시퀀스의 뒷부분이 가진 정보가 더 유용할 것이라고 예상하기 때문입니다. 특히 이 리뷰 데이터 세트의 경우 리뷰의 앞부분보다는 뒷부분에 더 결정적이고 중요한 소감을 말할 가능성이 높습니다. 만약 뒷부분을 자르려면 매개변수 `truncating`의 디폴트인 `pre`가 아닌 `post`를 지정합니다.\n",
        "\n",
        "이번에는 `train_seq`의 여섯 번째 샘플을 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "-YM5z0nQhFrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd5IDYyGVTNW",
        "outputId": "c6082a3e-5eb8-4605-cbe9-190e886e769c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   1   2 195  19  49   2   2 190   4   2 352   2 183  10\n",
            "  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2\n",
            "   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2\n",
            "   2  95  14 238  56 129   2  10  10  21   2  94 364 352   2   2  11 190\n",
            "  24 484   2   7  94 205 405  10  10  87   2  34  49   2   7   2   2   2\n",
            "   2   2 290   2  46  48  64  18   4   2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞부분 원소 4개가 0입니다. 여섯 번째 샘플 길이는 96입니다. 시퀀스의 앞부분을 자르는 것과 같은 이치로써 패딩 토큰 또한 시퀀스의 뒷부분이 아닌 앞부분에 추가됩니다. 시퀀스의 마지막에 구성된 단어가 셀의 은닉 상태에 가장 큰 영향을 미칠 가능성이 높으므로 뒷부분에 패딩을 추가하는 것은 선호되는 방법이 아닙니다. 만약 패딩을 뒷부분에 추가하려면 매개변수 `padding`의 디폴트인 `pre`를 `post`로 지정합니다.\n",
        "\n",
        "검증 데이터 세트의 길이도 100으로 지정하겠습니다."
      ],
      "metadata": {
        "id": "7zBdbdMnYyEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_seq = pad_sequences(val_input, maxlen=100)\n",
        "print(val_seq)\n",
        "print(val_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS2p_k2DaPWU",
        "outputId": "323fcb4c-f70f-4b9f-ccc4-db054e2c80cc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 32   2 225 ...  14  58   2]\n",
            " [ 53   2   8 ...   7  32   2]\n",
            " [  0   0   0 ...   2  33  32]\n",
            " ...\n",
            " [383   2 120 ...  16  99  76]\n",
            " [106 345  12 ... 120   2 156]\n",
            " [  4 114  21 ...   4   2   2]]\n",
            "(5000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **순환 신경망 만들기**"
      ],
      "metadata": {
        "id": "IT8V0OyFxBxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스가 제공하는 여러 순환층 클래스 중 가장 간단한 클래스는 `SimpleRNN`입니다. 이 클래스는 챕터 7의 파트 1에서 설명한 것과 유사한 기능을 가집니다. IMDB 리뷰 분류 문제는 이진 분류 문제입니다. 따라서 마지막 출력층은 유닛 1개를 가지고 시그모이드 활성화 함수를 사용해야 합니다. 먼저 `Sequential` 클래스로 생성한 코드를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "Pk1Ujt-FcuY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.SimpleRNN(8, input_shape=(100, 500)))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "SXOXbAqWdQQi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금까지 살펴왔던 코드와 비슷한 형태입니다. 차이점이라면 `Dense` 클래스나 `Conv2D` 클래스 대신 `SimpleRNN` 클래스를 사용한 것입니다. `SimpleRNN` 클래스의 디폴트 활성화 함수는 하이퍼볼릭 탄젠트 함수인 `tanh`이며 다른 함수를 따로 지정하지 않았으므로 디폴트를 그대로 사용합니다.\n",
        "\n",
        "입력 차원은 (100, 500)입니다. 첫 번째 차원은 샘플 길이가 100이므로 100입니다. 두 번째 차원이 500인 이유는 자세하게 설명할 필요가 있습니다. `train_seq`와 `val_seq`는 문제가 하나 있습니다. 토큰을 정수로 변환한 이 데이터를 신경망에 주입하면 큰 정수가 큰 활성화 출력을 만듭니다. 큰 정수일수록 영향력이 큰 것입니다. 그러나 이 정수 간에는 어떠한 관련성도 없습니다. 예컨대 더 큰 정수인 토큰 20을 더 작은 정수인 토큰 10보다 중요시할 이유가 없습니다. 단순한 정숫값을 신경망에 입력하려면 정숫값의 크기 속성을 없애고 각 정수를 고유하게 표현해야 합니다. 이를 구현할 방법은 원-핫 인코딩입니다. 토큰 10을 원-핫 인코딩으로 바꾸면 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ..., 0이 됩니다. 열한 번째 원소만 1이고 나머지는 0입니다. 이 배열의 길이가 중요합니다. 처음 `imdb.load_data()` 메서드로 데이터를 생성할 때 단어를 500개만 사용하도록 지정했으므로 고유 단어는 500개입니다. 훈련 데이터 세트에 포함될 수 있는 정숫값 범위는 패딩 토큰인 0부터 499까지입니다. 이 범위를 원-핫 인코딩으로 표현하면 배열 길이는 500이 됩니다. 원-핫 인코딩을 수행하는 케라스의 유틸리티는 `keras.utils` 패키지의 `to_categorical()` 메서드입니다. 아래처럼 메서드에 정수 배열을 입력하면 원-핫 인코딩된 배열을 생성합니다."
      ],
      "metadata": {
        "id": "2QXpL1cll36j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_oh = keras.utils.to_categorical(train_seq)\n",
        "print(train_oh)\n",
        "print(train_oh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0rhFqDXR8FL",
        "outputId": "2f54126c-09ab-44c4-da25-88012999a3f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]]]\n",
            "(20000, 100, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정수마다 500차원 배열로 바뀌었으므로 (20000, 100, 500) 크기가 됐습니다. 이처럼 샘플 데이터 크기가 1차원 정수 배열 (100, )에서 2차원 배열(100, 500)으로 바뀌면서 입력값인 `input_shape`를 (100, 500)으로 지정했습니다.\n",
        "\n",
        "`train_oh`의 첫 번째 샘플의 첫 번째 토큰 10이 어떻게 인코딩됐는지 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "pmp73jKmSK3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 샘플의 첫 번째 토큰 10을 확인합니다.\n",
        "print(train_seq[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKX-hSsXU0w6",
        "outputId": "81242d5e-3d3a-441b-f585-4dbe15841cf8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2\n",
            "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
            "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
            "   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91\n",
            "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
            "   6   2  46   7  14  20  10  10 470 158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 샘플의 첫 번째 토큰10이 원-핫 인코딩된 결과를 확인합니다.\n",
        "print(train_oh[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oN3Ti13T70t",
        "outputId": "04006a1d-e131-4c4b-f8cd-db4912f9b4e1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "열한 번째만 1이고 나머지는 0입니다. 본서에서는 `print(train_oh[0][0][:12])`로 앞부분 원소만 출력했으나 여기서는 전체를 출력해 봤습니다.\n",
        "\n",
        "아래처럼 모든 원소를 더하면 당연히 1이 됩니다. 원소 하나만 1이기 때문입니다."
      ],
      "metadata": {
        "id": "_jVKhT83VK6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(train_oh[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgNQMWrAVjtk",
        "outputId": "a9a95f07-f641-4893-ae02-22b9ac819eb0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`val_seq`도 원-핫 인코딩을 수행하겠습니다."
      ],
      "metadata": {
        "id": "-lCeRucZW1Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_oh = keras.utils.to_categorical(val_seq)\n",
        "print(val_oh[0])\n",
        "print(val_oh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_FIqCw1W5Za",
        "outputId": "bc94ba0a-6b34-45bb-80d6-942c877719a0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "(5000, 100, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 데이터 세트를 준비했습니다.\n",
        "\n",
        "모델 구조를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "4__EKWKUWz3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRIYt-_gXLiG",
        "outputId": "ed582b46-8b4b-42e8-da1c-dabe7d8b085e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 8)                 4072      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,081\n",
            "Trainable params: 4,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`SimpleRNN`에 전달할 샘플 크기는 (100, 500)이지만 이 순환층은 마지막 타임스텝의 은닉 상태만 출력합니다. 따라서 출력 크기가 순환층의 유닛 개수와 동일한 8입니다(위에서 8로 지정했습니다).\n",
        "\n",
        "순환층에 사용된 모델 파라미터 개수를 산출해 보겠습니다. 입력 토큰은 500차원의 원-핫 인코딩 배열이며, 이 배열이 순환층의 유닛 8개와 완전히 연결되므로 가중치 개수는 500 x 8 = 4,000개입니다. 순환층의 은닉 상태는 다시 다음 타임스텝에 사용되기 위해 또 다른 가중치와 곱해집니다. 이 은닉 상태도 순환층의 유닛과 완전히 연결되므로 가중치는 8(은닉 상태 크기) x 8(유닛 개수) = 64개가 됩니다. 유닛마다 절편 하나가 존재하므로 총 파라미터 개수는 4,000 + 64 + 8 = 4,072개입니다."
      ],
      "metadata": {
        "id": "Ix7-4-TrXRKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **순환 신경망 훈련하기**"
      ],
      "metadata": {
        "id": "KhAcqoM6xBvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "순환 신경망은 완전 연결 신경망 및 합성곱 신경망과 모델을 생성하는 방법은 다르지만 훈련하는 방법은 같습니다. 아래 코드로 구현하고 설명을 이어가겠습니다."
      ],
      "metadata": {
        "id": "Ud1IZ_aNvHic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 RMSprop의 학습률 0.001을 사용하지 않기 위해 \n",
        "# 별도로 RMSprop 객체를 생성하여 학습률을 0.0001로 지정합니다.\n",
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "history = model.fit(train_oh, train_target, epochs=100, batch_size=64, \n",
        "                    validation_data=(val_oh, val_target),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyPyuZeZvpZE",
        "outputId": "23575836-718d-4fff-bf49-76960c903306"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "313/313 [==============================] - 14s 41ms/step - loss: 0.6970 - accuracy: 0.5132 - val_loss: 0.6916 - val_accuracy: 0.5322\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.6794 - accuracy: 0.5745 - val_loss: 0.6731 - val_accuracy: 0.5940\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.6631 - accuracy: 0.6206 - val_loss: 0.6576 - val_accuracy: 0.6268\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 12s 40ms/step - loss: 0.6427 - accuracy: 0.6552 - val_loss: 0.6363 - val_accuracy: 0.6632\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.6209 - accuracy: 0.6873 - val_loss: 0.6182 - val_accuracy: 0.6896\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.5993 - accuracy: 0.7127 - val_loss: 0.6001 - val_accuracy: 0.7016\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.5797 - accuracy: 0.7311 - val_loss: 0.5815 - val_accuracy: 0.7188\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.5615 - accuracy: 0.7449 - val_loss: 0.5700 - val_accuracy: 0.7256\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 12s 40ms/step - loss: 0.5444 - accuracy: 0.7564 - val_loss: 0.5500 - val_accuracy: 0.7366\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.5301 - accuracy: 0.7638 - val_loss: 0.5378 - val_accuracy: 0.7480\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.5160 - accuracy: 0.7725 - val_loss: 0.5263 - val_accuracy: 0.7566\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 12s 40ms/step - loss: 0.5038 - accuracy: 0.7799 - val_loss: 0.5158 - val_accuracy: 0.7640\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4935 - accuracy: 0.7841 - val_loss: 0.5076 - val_accuracy: 0.7688\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4836 - accuracy: 0.7909 - val_loss: 0.5005 - val_accuracy: 0.7698\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4751 - accuracy: 0.7936 - val_loss: 0.4935 - val_accuracy: 0.7732\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4682 - accuracy: 0.7969 - val_loss: 0.4866 - val_accuracy: 0.7770\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4611 - accuracy: 0.7980 - val_loss: 0.4866 - val_accuracy: 0.7738\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4552 - accuracy: 0.8013 - val_loss: 0.4816 - val_accuracy: 0.7738\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4504 - accuracy: 0.8027 - val_loss: 0.4778 - val_accuracy: 0.7784\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4458 - accuracy: 0.8049 - val_loss: 0.4769 - val_accuracy: 0.7774\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 12s 40ms/step - loss: 0.4418 - accuracy: 0.8067 - val_loss: 0.4703 - val_accuracy: 0.7810\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.4383 - accuracy: 0.8076 - val_loss: 0.4669 - val_accuracy: 0.7824\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.4351 - accuracy: 0.8091 - val_loss: 0.4646 - val_accuracy: 0.7846\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4329 - accuracy: 0.8105 - val_loss: 0.4661 - val_accuracy: 0.7826\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4300 - accuracy: 0.8118 - val_loss: 0.4629 - val_accuracy: 0.7838\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 12s 40ms/step - loss: 0.4278 - accuracy: 0.8138 - val_loss: 0.4708 - val_accuracy: 0.7784\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4260 - accuracy: 0.8138 - val_loss: 0.4635 - val_accuracy: 0.7834\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 12s 40ms/step - loss: 0.4238 - accuracy: 0.8142 - val_loss: 0.4597 - val_accuracy: 0.7856\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4222 - accuracy: 0.8145 - val_loss: 0.4587 - val_accuracy: 0.7860\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 12s 40ms/step - loss: 0.4204 - accuracy: 0.8155 - val_loss: 0.4596 - val_accuracy: 0.7852\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4185 - accuracy: 0.8177 - val_loss: 0.4593 - val_accuracy: 0.7850\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.4174 - accuracy: 0.8170 - val_loss: 0.4598 - val_accuracy: 0.7856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "32번째 에포크에서 조기 종료 됐습니다. 검증 데이터 세트에 대한 정확도는 약 78.5%입니다.\n",
        "\n",
        "훈련 손실과 검증 손실을 그래프로 그려 보겠습니다."
      ],
      "metadata": {
        "id": "vRnPmqAi1ITH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "FhavMoI21ayd",
        "outputId": "fa1283fd-a6f5-4d02-e322-c71a114048b1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 손실은 지속적으로 감소하지만 검증 손실은 대략 20번째 에포크에서 감소 정도가 덜합니다. 적절한 에포크에서 훈련을 멈췄습니다. \n",
        "\n",
        "한 가지 고려할 점이라면 원-핫 인코딩을 수행한 데이터는 입력 데이터가 커져서 메모리 소모가 많습니다. 데이터 크기를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "ni-9BKYy1vyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq.nbytes, train_oh.nbytes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ban3XeKz2NZi",
        "outputId": "9ec35a77-09a4-44da-bca2-ad8aec542985"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8000000 4000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰 1개를 500차원으로 늘렸으므로 500배 정도 커진 셈입니다. 훈련 데이터가 커질수록 압도적인 크기로 커지기 때문에 결코 적절한 방법은 아닙니다. 아래 파트에서 더 나은 단어 표현 방법을 살펴 보겠습니다."
      ],
      "metadata": {
        "id": "5DtTckqU2WgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **단어 임베딩을 사용하기**"
      ],
      "metadata": {
        "id": "iy34IMEZxBtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "작업 중\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "k9zCm_2mOszC"
      }
    }
  ]
}