{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7-2 심층 신경망.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/LNbScuvC5LBCrMZqssAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Deep-learning_Theory/blob/main/7-2%20%EC%8B%AC%EC%B8%B5%20%EC%8B%A0%EA%B2%BD%EB%A7%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7-2 심층 신경망**"
      ],
      "metadata": {
        "id": "BqPF59nyrmb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "인공 신경층에 여러 층을 추가하여 심층 신경망을 생성하겠습니다. 일반 신경망의 성능을 제고하는 작업입니다."
      ],
      "metadata": {
        "id": "QlrNLq-fdamo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2개의 층**"
      ],
      "metadata": {
        "id": "xNmTOLMAroMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전 챕터에서 사용했던 패션 MNIST 데이터 세트를 가져오겠습니다. 픽셀 값을 0 ~ 1 사이로 좁히고, 2차원 배열을 1차원 배열로 펼친 후 훈련 세트에서 검증 세트를 분리하겠습니다."
      ],
      "metadata": {
        "id": "HB6B6mYfdsKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ZB-thUn8eJ_z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**심층 신경망(deep neural network, DNN)**을 생성하기 위해 기존 신경망 모델에 층 2개를 추가해 보겠습니다. 입력층과 출력층 사이에 새로운 밀집층 2개를 추가하는 것입니다. 추가할 밀집층은 **은닉층(hidden layer)**이라고 부릅니다.\n",
        "\n",
        "출력층의 활성화 함수는 적용할 수 있는 종류가 제한됩니다. 이진 분류의 경우 시그모이드 함수를 적용하고, 다중 분류의 경우 소프트맥스 함수를 적용합니다. 반면 은닉층의 활성화 함수는 자유롭게 적용할 수 있습니다. 참고로 회귀 문제에서는 활성화 함수를 적용할 필요가 없습니다(`Dense` 클래스의 `activation` 매개변수에 값을 지정하지 않습니다). 회귀 출력은 임의의 숫자이므로 출력층의 선형 방정식에 따라 도출된 값을 그대로 출력하기 때문입니다.\n",
        "\n",
        "은닉층에 많이 사용하는 함수는 시그모이드 함수입니다. 시그모이드 함수는 유닛의 출력값을 0 ~ 1 사이로 압축합니다. 시그모이드 활성 함수를 사용한 은닉층과 소프트맥스 함수를 사용한 출력층을 생성해 보겠습니다."
      ],
      "metadata": {
        "id": "LU8ulnp8h8DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망의 첫 번째 층(여기서는 은닉층)에는 `input_shape` 매개변수에 입력 크기를 지정합니다.\n",
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
        "# 출력층을 생성합니다.\n",
        "dense2 = keras.layers.Dense(10, activation='softmax')"
      ],
      "metadata": {
        "id": "yYImKEonmbF1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "은닉층에 지정한 유닛은 100개지만 특별한 기준을 토대로 지정한 것은 아닙니다. 유닛 개수에 따라 성능이 좌우되므로 적합한 유닛 개수를 지정하는 일에는 상당한 노하우가 필요합니다. 다만 한 가지 조건이 있습니다. 출력층의 유닛보다 많은 유닛을 지정해야 합니다. 출력층의 유닛이 10개인데 은닉층에 이보다 더 적은 유닛을 지정하면 부족한 정보가 전달될 것입니다."
      ],
      "metadata": {
        "id": "cNrql1oCnL-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **심층 신경망 만들기**"
      ],
      "metadata": {
        "id": "Iw6TK8E2roJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Dense` 클래스로 생성한 두 인스턴스를 사용하여 심층 신경망을 생성해 보겠습니다."
      ],
      "metadata": {
        "id": "k3-wcCaTqce9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 여러 층을 추가하려면 리스트에 담아 지정합니다. 단, 출력층은 마지막 원소로 전달합니다. \n",
        "model = keras.Sequential([dense1, dense2])"
      ],
      "metadata": {
        "id": "BgF9ekVep5YL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 `summary()` 메서드를 호출하여 각 층에 대한 정보를 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "w9IVcyTmrXQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "x8mglEDyr3jj",
        "outputId": "f244be7d-edec-4787-b260-5905bc778bd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "은닉층과 출력층이 순차로 나열되었습니다. 은닉층의 출력 크기인 `(None, 100)`에서 첫 번째 차원인 `None`은 샘플 개수를 의미합니다. 아직 샘플 개수가 정의되지 않았으므로 `None`입니다. `fit()` 메서드에 훈련 데이터를 주입하면 이 데이터를 한꺼번에 사용하지 않고 나눠서 수차례에 걸쳐 경사 하강법(**미니배치 경사 하강법**)을 수행합니다. 케라스의 미니배치 크기는 기본적으로 32개이며 `fit()` 메서드의 `batch_size` 매개변수에 지정하여 크기를 변경할 수 있습니다. 따라서 샘플 개수를 `None`으로 두고 어떤 배치 크기에도 유연하게 대응하게 하는 것입니다. 이렇게 신경망 층에 입력되거나 출력되는 배열의 첫 번째 차원을 **배치 차원**이라고 부릅니다. 두 번째 차원인 `100`은 유닛 개수입니다.\n",
        "\n",
        "`Param #`은 모델 파라미터 개수를 의미합니다. 각 층의 모델 파라미터 개수에 대한 산출 공식은 아래와 같습니다. 참고로 각 유닛 개수와 절편 개수는 동수입니다.\n",
        "\n",
        "- `dense`: 입력층 픽셀 784개 x 은닉층 유닛 100개 + 절편 100개 = 78,500개\n",
        "\n",
        "- `dense_1`: 은닉층 유닛 100개 x 출력층 유닛 10개 x 절편 10개 = 1,010개\n",
        "\n",
        "총 모델 파라미터 개수와 훈련될 파라미터 개수는 79,510개로 동수입니다. 경사 하강법으로 훈련되지 않는 파라미터를 가진 층도 있으므로 `Non-trainable params`는 0입니다. "
      ],
      "metadata": {
        "id": "GsnbAerYrjMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **층을 추가하는 다른 방법**"
      ],
      "metadata": {
        "id": "7cHE49HBrntv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "층을 추가한 위 방법과 다른 방법도 있습니다. `Sequential` 클래스를 이용하는 방법입니다. 아래 코드로 구현하겠습니다."
      ],
      "metadata": {
        "id": "za3RIVMcM3DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 층과 모델에 이름을 부여하기 위해 `name` 매개변수에 값을 지정합니다.\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
        "    keras.layers.Dense(10, activation='softmax', name='output')\n",
        "    ], name='fashion_MNIST_model')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhYPfbAoNXlY",
        "outputId": "6668be50-931c-41b7-db03-259da3ab52b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"fashion_MNIST_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다만 이 방법을 사용하면 여러 층을 추가할 때 클래스 생성자가 길어지고 다른 조건에 따라 층을 추가하기도 어렵습니다. 아래 방법처럼 `add()` 메서드를 사용하는 방법이 가장 널리 사용됩니다."
      ],
      "metadata": {
        "id": "XzqVsDXGPD4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(name='fashion_MNIST_model')\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax', name='output'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4rf4pelQCuu",
        "outputId": "334b3b89-3c15-490e-b984-f98d7c93f839"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"fashion_MNIST_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 훈련을 수행해 보겠습니다."
      ],
      "metadata": {
        "id": "VMXZsTq5QXIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6LTegexQbZM",
        "outputId": "a7c31a05-ee9b-4b99-ec0c-5db38ff938a6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5670 - accuracy: 0.8092\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4077 - accuracy: 0.8518\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3730 - accuracy: 0.8648\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3513 - accuracy: 0.8716\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3351 - accuracy: 0.8785\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81b8612990>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전 챕터의 결과보다 높은 정확도가 도출됐습니다. 이렇게 몇 층만 추가해도 성능 향상을 도모할 수 있습니다. "
      ],
      "metadata": {
        "id": "Kxw6sPteRq-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **렐루 함수**"
      ],
      "metadata": {
        "id": "dNII2NpBrnrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**렐루 함수(ReLU function)**는 이미지 분류 문제에서 높은 성능을 낼 수 있는 활성화 함수이며 심층 신경망에서 매우 뛰어납니다. 초창기 인공 신경망의 은닉층에는 시그모이드 함수가 많이 사용됐습니다. 그러나 이 함수는 그래프 상에서 보면 좌우의 끝으로 향할수록 위 아래의 끝으로 붙기 때문에 올바른 출력을 생성하는 데 신속한 대응이 어렵습니다. 특히 심층 신경망일수록 효과가 누적되면서 학습이 더 어려워집니다. 이를 개선할 목적으로 개발된 함수가 렐루 함수입니다. \n",
        "\n",
        "렐루 함수는 입력이 양수이면 활성화 함수가 없는 것처럼 입력을 통과시키고, 음수이면 0으로 만듭니다. [링크](https://blog.naver.com/totalcmd/222707125949)에서 확인할 수 있듯이, max(0, z)에서 z가 0보다 크면 z를 출력하고 z가 0보다 작으면 0을 출력합니다.\n",
        "\n",
        "참고로 이미지 분류 문제에 `Flatten` 클래스가 자주 사용됩니다. 이전에는 이미지 파일을 `reshape()` 메서드를 사용하여 1차원으로 펼쳤지만 이 클래스를 사용하면 모든 작업을 한번에 수행합니다. 이 클래스를 층처럼 입력층과 은닉층 사이에 추가하므로 **Flatten 층**이라고 부릅니다. 다만 배치 차원을 제외하고 모든 나머지 입력 차원을 일렬로 펼치는 역할만 수행하므로 입력에 대한 가중치와 절편이 없습니다. 모델 성능에는 기여하지 않습니다. \n",
        "\n",
        "Flatten 층을 추가해 보겠습니다. 은닉층에 지정했던 `input_shape` 매개변수를 Flatten 층으로 옮기는 것이 중요합니다. 은닉층에 지정할 활성화 함수는 렐루 함수를 지정하겠습니다."
      ],
      "metadata": {
        "id": "p-1eT1z2R6I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(name='fashion_MNIST_model')\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu', name='hidden'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax', name='output'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xMwMd9gVQXF",
        "outputId": "acf5ec6d-9c0a-47cd-8595-00399b16bf1a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"fashion_MNIST_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 신경망은 깊이가 2인 심층 신경망입니다. Flatten 층은 모델 파라미터가 0이므로 학습을 위한 층이 아닙니다. \n",
        "\n",
        "Flatten 층을 추가하면 입력값 차원을 짐작하기 좋습니다. 케라스 API는 가능하다면 입력 데이터 전처리 과정을 모델에 전부 포함시키는 것을 추구합니다.\n",
        "\n",
        "모델을 훈련해 보겠습니다. 이번엔 `reshape()` 메서드를 사용하지 않은 전체 코드를 작성하겠습니다."
      ],
      "metadata": {
        "id": "SDQ-lgO2Vg2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2, random_state=42)\n",
        "\n",
        "model = keras.Sequential(name='fashion_MNIST_model')\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu', name='hidden'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax', name='output'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-V66FYYYkDF",
        "outputId": "f767989d-cce6-4be6-8600-418bb97e23d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5315 - accuracy: 0.8122\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3908 - accuracy: 0.8589\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3528 - accuracy: 0.8723\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3319 - accuracy: 0.8815\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3176 - accuracy: 0.8864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff054e8da90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 조금 더 향상됐습니다. 에포크를 높여 보겠습니다."
      ],
      "metadata": {
        "id": "NcbxsbgOabqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_scaled, train_target, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k-_gfHVaiS4",
        "outputId": "d9623968-701c-4e2a-ea55-bd3edb66ce18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3096 - accuracy: 0.8906\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2993 - accuracy: 0.8936\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2886 - accuracy: 0.8981\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2816 - accuracy: 0.8999\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2741 - accuracy: 0.9041\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2694 - accuracy: 0.9064\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2629 - accuracy: 0.9086\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2574 - accuracy: 0.9098\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2538 - accuracy: 0.9115\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2494 - accuracy: 0.9136\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38d0377c10>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_scaled, train_target, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFLRXPZga1hx",
        "outputId": "9db570b8-fff6-42d3-e479-6332e1205af5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2435 - accuracy: 0.9153\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2390 - accuracy: 0.9179\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2334 - accuracy: 0.9190\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2345 - accuracy: 0.9181\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2257 - accuracy: 0.9234\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2277 - accuracy: 0.9226\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2217 - accuracy: 0.9251\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2192 - accuracy: 0.9264\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2181 - accuracy: 0.9279\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2115 - accuracy: 0.9279\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2092 - accuracy: 0.9301\n",
            "Epoch 12/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2087 - accuracy: 0.9305\n",
            "Epoch 13/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2024 - accuracy: 0.9322\n",
            "Epoch 14/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2019 - accuracy: 0.9321\n",
            "Epoch 15/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1998 - accuracy: 0.9327\n",
            "Epoch 16/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1945 - accuracy: 0.9359\n",
            "Epoch 17/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1967 - accuracy: 0.9353\n",
            "Epoch 18/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1886 - accuracy: 0.9370\n",
            "Epoch 19/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1922 - accuracy: 0.9377\n",
            "Epoch 20/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1850 - accuracy: 0.9385\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f37c8bcaf10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_scaled, train_target, epochs=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1SW_5ZRbn-m",
        "outputId": "5104f6c6-5a12-4e5e-cb55-cb7d5b3d3633"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1832 - accuracy: 0.9399\n",
            "Epoch 2/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1825 - accuracy: 0.9392\n",
            "Epoch 3/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1806 - accuracy: 0.9420\n",
            "Epoch 4/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1792 - accuracy: 0.9418\n",
            "Epoch 5/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1781 - accuracy: 0.9419\n",
            "Epoch 6/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1756 - accuracy: 0.9427\n",
            "Epoch 7/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1757 - accuracy: 0.9437\n",
            "Epoch 8/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1742 - accuracy: 0.9456\n",
            "Epoch 9/40\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1701 - accuracy: 0.9443\n",
            "Epoch 10/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1675 - accuracy: 0.9454\n",
            "Epoch 11/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1641 - accuracy: 0.9469\n",
            "Epoch 12/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1629 - accuracy: 0.9475\n",
            "Epoch 13/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1636 - accuracy: 0.9481\n",
            "Epoch 14/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1576 - accuracy: 0.9491\n",
            "Epoch 15/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1603 - accuracy: 0.9499\n",
            "Epoch 16/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1578 - accuracy: 0.9492\n",
            "Epoch 17/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1585 - accuracy: 0.9498\n",
            "Epoch 18/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1546 - accuracy: 0.9522\n",
            "Epoch 19/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1550 - accuracy: 0.9501\n",
            "Epoch 20/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1505 - accuracy: 0.9519\n",
            "Epoch 21/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1487 - accuracy: 0.9524\n",
            "Epoch 22/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1483 - accuracy: 0.9535\n",
            "Epoch 23/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1495 - accuracy: 0.9529\n",
            "Epoch 24/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1451 - accuracy: 0.9547\n",
            "Epoch 25/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1461 - accuracy: 0.9540\n",
            "Epoch 26/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1429 - accuracy: 0.9563\n",
            "Epoch 27/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1423 - accuracy: 0.9558\n",
            "Epoch 28/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1401 - accuracy: 0.9560\n",
            "Epoch 29/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1398 - accuracy: 0.9555\n",
            "Epoch 30/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1420 - accuracy: 0.9554\n",
            "Epoch 31/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1356 - accuracy: 0.9583\n",
            "Epoch 32/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1350 - accuracy: 0.9576\n",
            "Epoch 33/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1338 - accuracy: 0.9587\n",
            "Epoch 34/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1341 - accuracy: 0.9587\n",
            "Epoch 35/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1312 - accuracy: 0.9599\n",
            "Epoch 36/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1295 - accuracy: 0.9600\n",
            "Epoch 37/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1325 - accuracy: 0.9586\n",
            "Epoch 38/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1283 - accuracy: 0.9595\n",
            "Epoch 39/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1304 - accuracy: 0.9611\n",
            "Epoch 40/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1321 - accuracy: 0.9600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f37c8be7150>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "에포크를 높일수록 정확도가 향상됐습니다.\n",
        "\n",
        "검증 세트에서의 성능도 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "R07WZTuqcZX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVAGqUfQa4bm",
        "outputId": "ffcc542a-c758-4bfc-d1af-0381adb4300d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.9142 - accuracy: 0.8776\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9141854047775269, 0.8775833249092102]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **옵티마이저**"
      ],
      "metadata": {
        "id": "EEEZQIPJrnoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 `compile()` 메서드에서는 케라스의 기본 경사 하강법 알고리즘인 **RMSprop**(디폴트)를 사용했습니다. 케라스는 다양한 종류의 경사 하강법 알고리즘을 제공합니다. 이 알고리즘들을 **옵티마이저(optimizer)**라고 부릅니다. 이번 파트에서는 여러 옵티마이저를 적용해 보겠습니다.\n",
        "\n",
        "가장 기본적인 옵티마이저는 확률적 경사 하강법인 **SGD**입니다. 샘플 1개를 뽑아서 훈련하지 않고 미니배치를 사용합니다. SGD를 적용해 보겠습니다."
      ],
      "metadata": {
        "id": "pZQHTiS0dhBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "7rJePUJPrBhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습률을 변경하려면 `SGD` 클래스의 인스턴스를 생성하여 매개변수에 지정합니다."
      ],
      "metadata": {
        "id": "L-IvLebXuWQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(learning_rate=0.1)\n",
        "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "oZqw1gnmuhQS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 경사 하강법 옵티마이저 클래스는 아래와 같습니다. 이 옵티마이저 클래스에 매개변수를 추가로 지정하면 다른 옵티마이저가 됩니다. 많이 사용되는 옵티마이저 종류입니다.\n",
        "\n",
        "- `SGD(learning_rate=0.01)`: 기본 경사 하강법입니다. 학습률(`learning_rate`) 디폴트는 `0.01`이며 따로 지정하지 않아도 됩니다.\n",
        "\n",
        " - `momentum`: 0보다 큰 값을 지정하면 **모멘텀** 옵티마이저입니다. 예컨대 `momentum=0.9` 방식입니다(보통 `0.9` 이상을 지정합니다). 기본 경사 하강법에서는 `0`(디폴트)입니다. 이 옵티마이저는 그레이디언트 가속도를 사용하는 **모멘텀 최적화(momentum optimization)**를 사용합니다.\n",
        "\n",
        " - `nesterov=True`: **네스테로프 모멘텀** 옵티마이저입니다. 기본 경사 하강법에서는 `False`(디폴트)입니다. **네스테로프 모멘텀 최적화(nesterov momentum optimization, 네스테로프 가속 경사)**를 사용합니다. 모멘텀 최적화를 2번 반복하여 구현하며 기본 확률적 경사 하강법보다 좋은 성능을 발휘합니다.\n",
        "\n",
        "예시 코드는 아래와 같습니다."
      ],
      "metadata": {
        "id": "rVOCtBesvGpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)"
      ],
      "metadata": {
        "id": "jTXAXYDPx-ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "추가로 적응적 학습률 옵티마이저 또한 많이 사용됩니다. 모델이 최적점에 가까워질수록 학습률을 낮출 수 있고, 이를 통해 최적점에 안정적으로 수렴할 가능성이 높아집니다. 이 학습률을 **적응적 학습률(adaptive learning rate)**라고 부릅니다. 이 방식들은 학습률 매개변수를 튜닝하는 수고를 덜어줍니다. 적응적 학습률을 사용하는 대표적 옵티마이저는 **Adagrad**와 **RMSprop**입니다. `compile()` 메서드의 매개변수 `optimizer`에 각각 `'adagrad'`와 `'rmsprop'`로 지정하면 되지만 옵티마이저의 매개변수를 변경하려면 `Adagrad` 클래스와 `RMSprop` 클래스를 사용합니다. 목록으로 정리하자면 아래와 같습니다.\n",
        "\n",
        "- `Adagrad`: Adagrad 옵티마이저 클래스입니다. 그레이디언트 제곱을 누적하여 학습률을 나눕니다.\n",
        "\n",
        " - `learning_rate`: 학습률을 지정합니다. 디폴트는 `0.001`입니다.\n",
        "\n",
        " - `initial_accumulator`: 그레이디언트 제곱에 대한 누적값의 초깃값을 지정합니다. 디폴트는 `0.1`입니다.\n",
        "\n",
        "- `RMSprop`: RMSprop 옵티마이저 클래스입니다. Adagrad처럼 그레이디언트 제곱으로 학습률을 나누지만 최근의 그레이디언트를 사용하기 위해 지수 감소를 사용합니다.\n",
        "\n",
        " - `learning_rate`: 학습률을 지정합니다. 디폴트는 `0.001`입니다.\n",
        "\n",
        " - `rho`: 지수 감소 비율을 지정합니다. 디폴트는 `0.9`입니다."
      ],
      "metadata": {
        "id": "KPiBosxjyF56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 매개변수를 변경하지 않습니다.\n",
        "model.compile(optimizer='adagrad', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "# 매개변수를 변경합니다.\n",
        "adagrad = keras.optimizers.Adagrad(learning=0.1)\n",
        "model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "rmsprop = keras.optimizers.RMSprop(learning=0.1)\n",
        "model.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "atgZeuUA0UWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adam**은 모멘텀 최적화와 RMSprop의 장점을 접목한 적응적 학습률 옵티마이저입니다. RMSprop처럼 가장 먼저 시도할 만한 알고리즘입니다. 사용법은 다른 옵티마이저와 같습니다.\n",
        "\n",
        "- `Adam`: Adam 옵티마이저 클래스입니다.\n",
        "\n",
        " - `beta_1`: 모멘텀 최적화의 그레이디언트 지수 감소 평균을 조절합니다. 디폴트는 `0.9`입니다.\n",
        "\n",
        " - `beta_2`: RMSprop의 그레이디언트 제곱의 지수 감소 평균을 조절할 수 있습니다. 디폴트는 `0.999`입니다."
      ],
      "metadata": {
        "id": "GjjJn-l10pfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 매개변수를 변경하지 않습니다.\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "# 매개변수를 변경합니다.\n",
        "adam = keras.optimizers.Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "iNDiBwZW1I0c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam 클래스를 사용하여 모델을 훈련해 보겠습니다."
      ],
      "metadata": {
        "id": "OHm_hUOi4HqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(name='fashion_MNIST_model')\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu', name='hidden'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax', name='output'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0dOdt004RxV",
        "outputId": "e98705df-6df9-447c-a3dc-b466f7479f3e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5300 - accuracy: 0.8132\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3907 - accuracy: 0.8598\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3482 - accuracy: 0.8741\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3249 - accuracy: 0.8805\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3034 - accuracy: 0.8879\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff054daab10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "디폴트인 RMSprop를 사용했을 때와 비슷한 성능이 도출됐습니다.\n",
        "\n",
        "검증 세트에서의 성능을 확인하겠습니다."
      ],
      "metadata": {
        "id": "OAwFioUk4opL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuCZmVr95FHY",
        "outputId": "cfae3a15-86d4-4727-d97e-6f935cd2dc90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3553 - accuracy: 0.8700\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35530829429626465, 0.8700000047683716]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}
