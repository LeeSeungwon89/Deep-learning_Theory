{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcINrnSY+Fl7K82eZMr9v0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Deep-learning_Theory/blob/main/8-1%20%ED%95%A9%EC%84%B1%EA%B3%B1%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98%20%EA%B5%AC%EC%84%B1%20%EC%9A%94%EC%86%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8-1 합성곱 신경망의 구성 요소**"
      ],
      "metadata": {
        "id": "h1Ko3hFatU8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 챕터는 이미지 예시가 많은 챕터이므로 본서를 함께 참고하시는 편이 좋습니다. 개인 학습 위주이므로 이미지 첨부는 생략하겠습니다."
      ],
      "metadata": {
        "id": "Y9aC4BxkHxrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **합성곱**"
      ],
      "metadata": {
        "id": "kVqxSzfZtU5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**합성곱(convolution)**은 입력 데이터에 마법의 도장을 찍어서 유용한 특성만 드러나게 하는 것으로 비유할 수 있습니다. 밀집층에는 유닛마다 입력 개수만큼 가중치가 존재합니다. 모든 입력에 가중치를 곱하는 것입니다. 반면 합성곱 층은 입력 데이터 전체에 가중치를 곱하지 않고 일부에만 가중치를 곱합니다. 예컨대 밀집층에 유닛이 10개 존재한다면 가중치도 10개입니다. 반면 합성곱 층에 유닛이 10개 존재한다면 가중치는 10개가 아니라 3개입니다. 물론 가중치 개수는 임의로 정할 수 있습니다. 일종의 하이퍼파라미터입니다.\n",
        "\n",
        "유닛 10개, 가중치 3개가 존재한다고 가정하겠습니다. 각 유닛은 A, B, C, ..., I, J이며 총 10개이며, 가중치는 $w1$ ~ $w3$이며 총 3개입니다.\n",
        "\n",
        "1. 특성 A, B, C에 가중치 $W_1$ ~ $W_3$이 각각 곱해지고 절편이 더해져 출력 1개가 만들어집니다.\n",
        "\n",
        "1. 특성 B, C, D에 가중치 $W_1$ ~ $W_3$이 각각 곱해지고 절편이 더해져 출력 1개가 만들어집니다.\n",
        "\n",
        "1. 같은 과정을 반복합니다.\n",
        "\n",
        "1. 특성 H, I, J에 가중치 $W_1$ ~ $W_3$이 각각 곱해지고 절편이 더해져 출력 1개가 만들어집니다.\n",
        "\n",
        "출력 8개가 만들어집니다. 밀집층에서 출력이 10개 만들어지는 것과 달리 합성곱 층에서는 출력이 8개 만들어집니다. \n",
        "\n",
        "이렇게 입력 데이터 위를 이동하면서 같은 도장(가중치 3개)을 하나씩 찍는 것으로 볼 수 있습니다. 바법의 도장을 한번 찍을 때마다 출력 1개가 만들어지는 것입니다. 기실 합성곱에서는 유닛이 입력 데이터 위를 이동하면서 출력을 만들기 때문에 유닛으로 부르기 어색합니다. **합성곱 신경망(convolutional neural network, CNN)**에서는 완전 연결 신경망(밀집층만 사용한 신경망(밀집 신경망))에서의 유닛을 **필터(filter)** 또는 **커널(kernel)**이라고 부릅니다. 유닛과 필터, 커널을 구분 없이 부르기도 합니다. 다만 본서에서는 케라스 API와 이름을 맞추기 위해 유닛 개수(마법의 도장)는 필터로, 가중치를 커널로 부르고 있습니다.\n",
        "\n",
        "합성곱은 1차원뿐만 아니라 2차원 입력에도 적용할 수 있습니다. 2차원 배열은 4행 4열(4, 4), 필터의 커널 크기는 3행 3열(3, 3)로 가정하겠습니다. 이 가정 하에 아래 과정으로 합성곱을 수행합니다(도장으로 찍는다고 생각하면 쉽습니다).\n",
        "\n",
        "1. 1행 1열에서 3행 3열만큼 합성곱을 수행합니다.\n",
        "\n",
        "1. 1행 2열에서 3행 4열만큼 합성곱을 수행합니다.\n",
        "\n",
        "1. 2행 1열에서 4행 3열만큼 합성곱을 수행합니다.\n",
        "\n",
        "1. 2행 2열에서 4행 4열만큼 합성곱을 수행합니다.\n",
        "\n",
        "이렇게 출력 4개가 만들어집니다. 만들어진 출력은 2차원으로 배치됩니다. 2행 2열(2, 2)로 배치되며 출력 1은 (1, 1), 출력 2는 (1, 2), 출력 3은 (2, 1), 출력 4는 (2, 2)입니다. 이렇게 4행 4열이었던 2차원 배열을 2행 2열로 줄인 셈입니다. 합성곱을 통해 만들어진 출력을 **특성 맵(feature map)**이라고 합니다.\n",
        "\n",
        "합성곱 층에서 필터를 하나만 사용할 수 있는 것은 아닙니다. 여러 필터를 사용하면 특성 맵이 순차대로 쌓입니다. 예컨대 위 특성맵을 필터 3개로 만들면 3차원 배열(2, 2, 3)이 됩니다. 밀집층에 존재하는 유닛의 가중치가 모두 다르듯이 합성곱 층에 있는 필터의 가중치(커널)도 모두 다릅니다. 같은 가중치 필터를 사용할 이유가 없습니다.\n",
        "\n",
        "정리하자면 합성곱은 밀집층과 달리 2차원 형태를 유지하는 점에서 차이가 있습니다. 입력보다 훨씬 작은 크기의 커널을 사용하고, 입력의 위를 왼쪽에서 오른쪽으로, 위에서 아래로 이동하면서 2차원 특성 맵을 만듭니다. 이렇게 2차원 구조를 그대로 사용하므로 합성곱 신경망이 이미지 처리 문제에 뛰어난 성능을 발휘합니다."
      ],
      "metadata": {
        "id": "DaSMSbYYP0lK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **케라스 합성곱 층**"
      ],
      "metadata": {
        "id": "b70EFaf3tU22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스의 모든 층은 `keras.layers` 모듈에 구현됩니다. 합성곱 층도 같습니다. 합성곱은 `Conv2D` 클래스로 구현됩니다. 이 클래스에 대한 예시를 코드로 작성해 보겠습니다."
      ],
      "metadata": {
        "id": "Tzcx8R6GqByG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow improt keras\n",
        "\n",
        "keras.layers.Conv2D(10, kernel_size=(3, 3), activation='relu')"
      ],
      "metadata": {
        "id": "hqzcX9VHqZxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`10`은 필터 개수, `kernel_size`는 커널 크기입니다. 이 두 하이퍼파라미터는 반드시 지정해야 합니다. 커널 크기는 대체적으로 (3, 3) 또는 (5, 5)가 권장됩니다. 합성곱 층을 추가하려면 이전에 Dense 층을 사용했던 자리에 Conv2D 층을 추가하면 됩니다. \n",
        "\n",
        "합성곱 신경망의 정의는 일반적으로 1개 이상의 합성곱 층을 사용한 인공 신경망을 의미합니다. 합성곱 층만 사용한 신경망이 아니라 밀집층도 포함된 신경망입니다. 클래스에 대한 확률을 계산하기 위해 마지막 층에는 클래스 개수만큼 유닛을 가진 밀집층을 두는 것이 일반적이기 때문입니다.  \n",
        "\n",
        "참고로 특성 맵은 활성화 함수를 적용한 후의 값입니다. 완전 연결 신경망에서처럼 합성곱 신경망에서도 종종 활성화 함수를 언급하지 않습니다. 일반적으로 특성 맵은 활성화 함수를 통과한 값을 나타내지만, 활성곱에서는 활성화 출력이라는 표현을 쓰지 않습니다. 밀집층과 마찬가지로 합성곱 층에서도 렐루 함수를 많이 사용합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "oyYtHKwKqysu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **패딩과 스트라이드**"
      ],
      "metadata": {
        "id": "SmJt524OtU0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 입력 (4, 4) 커널 (3, 3)을 적용하여 (2, 2) 크기의 특성 맵을 만들었습니다. 만약 커널을 (3, 3)으로 고정하고 출력 크기를 입력 크기와 동일한 (4, 4)로 만들려면(입력과 특성 맵의 크기를 동일하게 만들려면) 더 큰 입력에 합성곱을 수행하는 것처럼 조치해야 합니다. 예컨대 실제 입력 크기인 (4, 4)를 (6, 6)로 만들고 합성곱을 수행한다고 가정하겠습니다. 입력 배열 (6, 6)은 가장 테두리에 위치한 칸인 (1, 1) ~(1, 6), (2, 1) ~ (6, 1), (6, 1) ~ (6, 6), (1, 6) ~ (6, 6)에 가상의 원소가 들어있고, 본래 입력인 (4, 4)는 가상의 원소가 들어있는 테두리 칸의 가운데에 위치합니다. 결론적으로 입력 (6, 6)에 커널 (3, 3)을 적용한다면 출력은 (4, 4)가 됩니다.\n",
        "\n",
        "이렇게 입력 배열 주위를 가상의 원소로 채우는 작업을 **패딩(padding)**이라고 부릅니다. 실제 입력값이 아니므로 합성곱 신경망에서는 주로 가상의 원소를 0으로 채웁니다. 모든 테두리 칸을 같은 값인 0으로 채우는 작업을 **세임 패딩(same padding)**이라고 부릅니다. 패딩을 수행하는 이유는 커널이 도장 찍을 횟수를 늘려주는 것에 한정됩니다. 실제 값이 0으로 채워져 있기 때문에 계산 자체에 아무런 영향이 없습니다.\n",
        "\n",
        "반면 패딩을 수행하지 않고 순수한 입력 배열에서만 합성곱을 수행하여 (입력보다 특성 맵의 크기가 작은)특성 맵을 만드는 경우는 **밸리드 패딩(valid padding)**이라고 부릅니다.\n",
        "\n",
        "합성곱에서 패딩을 주로 사용하는 이유는 원소들이 최대한 많은 횟수만큼 계산되도록 조치하기 위함입니다. 원소마다 계산되는 횟수에 차이가 생기면 덜 계산된 원소는 원소가 지닌 중요한 정보를 잃게 됩니다. 특히 주변에 위치한 원소는 계산 횟수가 적기 때문에 정보를 잃어버리기 쉽습니다. 따라서 합성곱 신경망에서 주로 사용하는 세임 패딩은 가장자리에 위치한 원소가 정보를 잃지 않도록 도움을 줍니다. 세임 패딩은 `Conv2D` 클래스의 `padding` 매개변수에 `'same'`으로 지정하면 사용할 수 있습니다. 디폴트는 `'valid'`로 밸리드 패딩을 의미합니다.\n",
        "\n",
        "물론 합성곱 연산을 두 칸씩 이동하도록 지정할 수도 있습니다. 도장이 이동하는 칸의 개수라고 생각하면 쉽습니다. 이동하는 칸수가 늘면 커널 도장을 찍는 횟수는 줄고 특성 맵의 크기도 작아집니다. 이 이동의 크기를 **스트라이드(stride)**라고 부르며 매개변수 `strides`에 숫자로 지정하여 조정할 수 있습니다. 디폴트는 `1`입니다. 대부분 디폴트 값을 사용하므로 조정하는 경우는 드뭅니다."
      ],
      "metadata": {
        "id": "Tu9IadVAs5TE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **풀링**"
      ],
      "metadata": {
        "id": "rejRcKeltUyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**풀링(pooling)**은 특성 맵의 가로세로 크기를 줄이는 역할을 수행합니다. 다만 특성 맵의 개수는 줄지 않습니다. 예컨대 (2, 2, 3) 특성 맵에 풀링을 적용하면 마지막 차원 개수는 그대로지만 (1, 1, 3) 크기로 줄어듭니다. 일반적으로 특성 맵의 값은 실수입니다.\n",
        "\n",
        "풀링도 합성곱처럼 입력 위를 이동하면서 도장을 찍습니다. 하지만 풀링에는 가중치가 없습니다. 도장을 찍은 영역에서 가장 큰 값(**최대 풀링(max pooling)**)을 고르거나 평균값(**평균 풀링(average pooling)**)을 계산합니다. 풀링은 합성곱 층과 구분되므로 풀링 층으로 부를 수 있습니다. 예를 들면 (4, 4) 특성 맵에 (2, 2) 최대 풀링을 적용한다면 두 칸씩 (반드시) 가로세로로 이동하면서 최종적으로 (2, 2) 출력을 만듭니다. 여기서 중요한 점이라면 커널의 경우 겹치는 부분을 이동하는 것과 달리 풀링은 겹치지 않고 이동하므로 두 칸씩 이동하며(스트라이드가 2), (4, 4) 특성맵에 존재하는 (2, 2)만큼의 최댓값을 배열에 차례대로 하나씩 뽑아서 만듭니다. 특성 맵이 여러 개라면 같은 작업을 반복하여 새 특성 맵이 기존 특성 맵 개수만큼 만들어지며, 특성 맵이 10개였다면 풀링을 거친 특성 맵 개수도 10개가 됩니다. 합성곱 신경망에서는 합성곱 층과 풀링 층에서 출력되는 값을 동일하게 특성 맵이라고 부릅니다. \n",
        "\n",
        "최대 풀링을 수행하려면 `MaxPooling2D` 클래스를 사용합니다."
      ],
      "metadata": {
        "id": "BbLoXZkcysga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.MaxPooling2D(2, strides=2, padding='valid')"
      ],
      "metadata": {
        "id": "OgO2gfA2qMbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`2`는 풀링 크기이며 대부분 이 값을 사용합니다. 가로세로 크기를 절반으로 줄입니다. 풀링 크기를 다르게 지정하려면 정수의 튜플(예컨대 (2, 3))로 지정할 수 있으나 변경하는 경우는 거의 없습니다. 아울러 풀링은 가중치가 없고 풀링 크기와 스트라이드가 같으며 패딩이 없으므로 매개변수 `strides`와 `padding`은 변경하는 경우가 거의 없습니다.\n",
        "\n",
        "평균 풀링을 수행하려면 `AveragePooling2D` 클래스를 사용합니다. 사용법은 `MaxPooling2D` 클래스와 동일합니다. 평균 풀링은 특성 맵의 중요한 정보를 평균하여 희석시킬 수 있으므로 최대 풀링을 더 많이 사용합니다."
      ],
      "metadata": {
        "id": "wOetBDgFqykg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **합성곱 신경망의 전체 구조**"
      ],
      "metadata": {
        "id": "Yp-vPcdStUvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 설명한 내용은 모두 합성곱 신경망을 구성하는 요소들입니다. 구성 순서를 목록으로 나열하면 아래와 같습니다.\n",
        "\n",
        "1. 입력층에 패딩을 적용합니다. 패딩은 텐서플로에서 자동으로 추가하므로 어떤 작업을 추가할 필요가 없습니다.\n",
        "\n",
        "1. 합성곱 층에서 필터가 이동하며 특성 맵을 생성합니다.\n",
        "\n",
        "1. 특성 맵에 풀링을 적용하여 가로세로 크기를 줄입니다.\n",
        "\n",
        "1. 가로세로 크기가 줄어든 특성 맵을 밀집층인 출력층에 전달하기 위해 배열을 1차원으로 펼칩니다. "
      ],
      "metadata": {
        "id": "C_Uu8clztADA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **컬러 이미지를 사용한 합성곱**"
      ],
      "metadata": {
        "id": "6Yd533IntUtE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "패션 MNIST 데이터 세트는 흑백 이미지로 구성되어 있으므로 2차원 배열로 표현될 수 있습니다. 그러나 컬러 이미지의 경우는 RGB(Red, Green, Blue) 채널로 구성되어 있어서 3차원 배열로 표시됩니다. 각 컬러마다 1차원씩 3차원으로 겹쳐진 이미지입니다. 이렇게 깊이가 깊은 입력에서 합성곱을 수행하려면 도장의 깊이도 깊어야 합니다. 입력 깊이와 커널 배열의 깊이가 같아야 합니다.\n",
        "\n",
        "예컨대 (4, 4, 3) 입력이 있다고 가정하면 (3, 3, 3) 커널에 해당하는 원소 27개에 가중치 27개를 곱하고 절편을 더하는 방식입니다. 2차원 합성곱과 같은 방식이지만 도장이 입력 깊이(3차원)만큼 들어간다고 볼 수 있습니다. 중요한 점이라면 출력은 필터 차원과 관계 없이 하나가 도출되어 (2, 2) 특성 맵이 만들어지게 됩니다.\n",
        "\n",
        "케라스 합성곱 층은 항상 3차원 입력을 기대합니다. 흑백 이미지가 입력되면 깊이 차원이 1인 3차원 배열로 변환하여 전달합니다. 예컨대 (28, 28) 배열이 전달되면 (28, 28, 1) 배열로 변환합니다. 원소 개수는 동일하되 차원만 달라집니다.\n",
        "\n",
        "이와 비슷한 경우라면 합성곱 층, 풀링 층, 그리고 합성곱 층이 다시 오는 경우입니다. 예컨대 처음 합성곱 층의 필터 개수가 5개이고 처음 풀링 층을 통과한 특성 맵이 (4, 4, 5)라고 가정하겠습니다. 두 번째 합성곱 층에서 필터의 너비와 높이가 각각 3이라면 입력의 깊이와 필터의 깊이가 같아야 하므로 이 필터의 커널 크기는 (3, 3, 5)가 됩니다. 3 x 3 x 5 = 45개만큼 가중치를 곱하고 절편을 더하여 출력 1개를 만듭니다. 만약 두 번째 합성곱 층의 필터 개수가 10개라면 특성 맵은 (2, 2, 10)이 됩니다. 이런 식으로 합성곱 신경망은 너비와 높이는 점점 줄고 깊이는 점점 깊어지는 것이 특징이며, 출력층 바로 전에 특성 맵을 펼쳐서 밀집층에 입력으로 사용합니다.\n",
        "\n",
        "합성곱 신경망에서 필터는 이미지에 있는 특징을 찾는 역할을 하는 것입니다. 처음에는 기본적인 특징(직선, 곡선 등)을 찾고, 층이 깊어질수록 다양하고 구체적인 특징을 감지하기 위해 필터 개수를 늘립니다. 아울러 특징이 이미지의 어느 위치에 놓여도 쉽게 감지할 수 있도록 너비와 높이 차원을 점점 줄여가는 것입니다. "
      ],
      "metadata": {
        "id": "PjZp_2Tsb9W-"
      }
    }
  ]
}