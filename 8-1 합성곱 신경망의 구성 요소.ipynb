{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8-1 합성곱 신경망의 구성 요소.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNta7+jci/9pTDw9ZL0Gqff",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Deep-learning_Theory/blob/main/8-1%20%ED%95%A9%EC%84%B1%EA%B3%B1%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98%20%EA%B5%AC%EC%84%B1%20%EC%9A%94%EC%86%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8-1 합성곱 신경망의 구성 요소**"
      ],
      "metadata": {
        "id": "h1Ko3hFatU8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 챕터는 이미지 예시가 많은 챕터이므로 본서를 함께 참고하시는 편이 좋습니다. 개인 학습 위주이므로 이미지 첨부는 생략하겠습니다."
      ],
      "metadata": {
        "id": "Y9aC4BxkHxrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **합성곱**"
      ],
      "metadata": {
        "id": "kVqxSzfZtU5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**합성곱(convolution)**은 입력 데이터에 마법의 도장을 찍어서 유용한 특성만 드러나게 하는 것으로 비유할 수 있습니다. 밀집층에는 유닛마다 입력 개수만큼 가중치가 존재합니다. 모든 입력에 가중치를 곱하는 것입니다. 반면 합성곱 층은 입력 데이터 전체에 가중치를 곱하지 않고 일부에만 가중치를 곱합니다. 예컨대 밀집층에 유닛이 10개 존재한다면 가중치도 10개입니다. 반면 합성곱 층에 유닛이 10개 존재한다면 가중치는 10개가 아니라 3개입니다. 물론 가중치 개수는 임의로 정할 수 있습니다. 일종의 하이퍼파라미터입니다.\n",
        "\n",
        "유닛 10개, 가중치 3개가 존재한다고 가정하겠습니다. 각 유닛은 A, B, C, ..., I, J이며 총 10개이며, 가중치는 $w1$ ~ $w3$이며 총 3개입니다.\n",
        "\n",
        "1. 특성 A, B, C에 가중치 $W_1$ ~ $W_3$이 각각 곱해지고 절편이 더해져 출력 1개가 만들어집니다.\n",
        "\n",
        "1. 특성 B, C, D에 가중치 $W_1$ ~ $W_3$이 각각 곱해지고 절편이 더해져 출력 1개가 만들어집니다.\n",
        "\n",
        "1. 같은 과정을 반복합니다.\n",
        "\n",
        "1. 특성 H, I, J에 가중치 $W_1$ ~ $W_3$이 각각 곱해지고 절편이 더해져 출력 1개가 만들어집니다.\n",
        "\n",
        "출력 8개가 만들어집니다. 밀집층에서 출력이 10개 만들어지는 것과 달리 합성곱 층에서는 출력이 8개 만들어집니다. \n",
        "\n",
        "이렇게 입력 데이터 위를 이동하면서 같은 도장(가중치 3개)을 하나씩 찍는 것으로 볼 수 있습니다. 바법의 도장을 한번 찍을 때마다 출력 1개가 만들어지는 것입니다. 기실 합성곱에서는 유닛이 입력 데이터 위를 이동하면서 출력을 만들기 때문에 유닛으로 부르기 어색합니다. **합성곱 신경망(convolutional neural network, CNN)**에서는 완전 연결 신경망(밀집층만 사용한 신경망(밀집 신경망))에서의 유닛을 **필터(filter)** 또는 **커널(kernel)**이라고 부릅니다. 유닛과 필터, 커널을 구분 없이 부르기도 합니다. 다만 본서에서는 케라스 API와 이름을 맞추기 위해 유닛 개수(마법의 도장)는 필터로, 가중치를 커널로 부르고 있습니다.\n",
        "\n",
        "합성곱은 1차원뿐만 아니라 2차원 입력에도 적용할 수 있습니다. 2차원 배열은 4행 4열(4, 4), 필터의 커널 크기는 3행 3열(3, 3)로 가정하겠습니다. 이 가정 하에 아래 과정으로 합성곱을 수행합니다(도장으로 찍는다고 생각하면 쉽습니다).\n",
        "\n",
        "1. 1행 1열에서 3행 3열만큼 합성곱을 수행합니다.\n",
        "\n",
        "1. 1행 2열에서 3행 4열만큼 합성곱을 수행합니다.\n",
        "\n",
        "1. 2행 1열에서 4행 3열만큼 합성곱을 수행합니다.\n",
        "\n",
        "1. 2행 2열에서 4행 4열만큼 합성곱을 수행합니다.\n",
        "\n",
        "이렇게 출력 4개가 만들어집니다. 만들어진 출력은 2차원으로 배치됩니다. 2행 2열(2, 2)로 배치되며 출력 1은 (1, 1), 출력 2는 (1, 2), 출력 3은 (2, 1), 출력 4는 (2, 2)입니다. 이렇게 4행 4열이었던 2차원 배열을 2행 2열로 줄인 셈입니다. 합성곱을 통해 만들어진 출력을 **특성 맵(feature map)**이라고 합니다.\n",
        "\n",
        "합성곱 층에서 필터를 하나만 사용할 수 있는 것은 아닙니다. 여러 필터를 사용하면 특성 맵이 순차대로 쌓입니다. 예컨대 위 특성맵을 필터 3개로 만들면 3차원 배열(2, 2, 3)이 됩니다. 밀집층에 존재하는 유닛의 가중치가 모두 다르듯이 합성곱 층에 있는 필터의 가중치(커널)도 모두 다릅니다. 같은 가중치 필터를 사용할 이유가 없습니다.\n",
        "\n",
        "정리하자면 합성곱은 밀집층과 달리 2차원 형태를 유지하는 점에서 차이가 있습니다. 입력보다 훨씬 작은 크기의 커널을 사용하고, 입력의 위를 왼쪽에서 오른쪽으로, 위에서 아래로 이동하면서 2차원 특성 맵을 만듭니다. 이렇게 2차원 구조를 그대로 사용하므로 합성곱 신경망이 이미지 처리 문제에 뛰어난 성능을 발휘합니다."
      ],
      "metadata": {
        "id": "DaSMSbYYP0lK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **케라스 합성곱 층**"
      ],
      "metadata": {
        "id": "b70EFaf3tU22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스의 모든 층은 `keras.layers` 모듈에 구현됩니다. 합성곱 층도 같습니다. 합성곱은 `Conv2D` 클래스로 구현됩니다. 이 클래스에 대한 예시를 코드로 작성해 보겠습니다."
      ],
      "metadata": {
        "id": "Tzcx8R6GqByG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow improt keras\n",
        "\n",
        "keras.layers.Conv2D(10, kernel_size=(3, 3), activation='relu')"
      ],
      "metadata": {
        "id": "hqzcX9VHqZxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`10`은 필터 개수, `kernel_size`는 커널 크기입니다. 이 두 하이퍼파라미터는 반드시 지정해야 합니다. 커널 크기는 대체적으로 (3, 3) 또는 (5, 5)가 권장됩니다. 합성곱 층을 추가하려면 이전에 Dense 층을 사용했던 자리에 Conv2D 층을 추가하면 됩니다. \n",
        "\n",
        "합성곱 신경망의 정의는 일반적으로 1개 이상의 합성곱 층을 사용한 인공 신경망을 의미합니다. 합성곱 층만 사용한 신경망이 아니라 밀집층도 포함된 신경망입니다. 클래스에 대한 확률을 계산하기 위해 마지막 층에는 클래스 개수만큼 유닛을 가진 밀집층을 두는 것이 일반적이기 때문입니다.  \n",
        "\n",
        "참고로 특성 맵은 활성화 함수를 적용한 후의 값입니다. 완전 연결 신경망에서처럼 합성곱 신경망에서도 종종 활성화 함수를 언급하지 않습니다. 일반적으로 특성 맵은 활성화 함수를 통과한 값을 나타내지만, 활성곱에서는 활성화 출력이라는 표현을 쓰지 않습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "oyYtHKwKqysu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **패딩과 스트라이드**"
      ],
      "metadata": {
        "id": "SmJt524OtU0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 입력 (4, 4) 커널 (3, 3)을 적용하여 (2, 2) 크기의 특성 맵을 만들었습니다. 만약 커널을 (3, 3)으로 고정하고 출력 크기를 입력 크기와 동일한 (4, 4)로 만들려면(입력과 특성 맵의 크기를 동일하게 만들려면) 더 큰 입력에 합성곱을 수행하는 것처럼 조치해야 합니다. 예컨대 실제 입력 크기인 (4, 4)를 (6, 6)로 만들고 합성곱을 수행한다고 가정하겠습니다. 입력 배열 (6, 6)은 가장 테두리에 위치한 칸인 (1, 1) ~(1, 6), (2, 1) ~ (6, 1), (6, 1) ~ (6, 6), (1, 6) ~ (6, 6)에 가상의 원소가 들어있고, 본래 입력인 (4, 4)는 가상의 원소가 들어있는 테두리 칸의 가운데에 위치합니다. 결론적으로 입력 (6, 6)에 커널 (3, 3)을 적용한다면 출력은 (4, 4)가 됩니다.\n",
        "\n",
        "이렇게 입력 배열 주위를 가상의 원소로 채우는 작업을 **패딩(padding)**이라고 부릅니다. 실제 입력값이 아니므로 합성곱 신경망에서는 주로 가상의 원소를 0으로 채웁니다. 모든 테두리 칸을 같은 값인 0으로 채우는 작업을 **세임 패딩(same padding)**이라고 부릅니다. 패딩을 수행하는 이유는 커널이 도장 찍을 횟수를 늘려주는 것에 한정됩니다. 실제 값이 0으로 채워져 있기 때문에 계산 자체에 아무런 영향이 없습니다.\n",
        "\n",
        "반면 패딩을 수행하지 않고 순수한 입력 배열에서만 합성곱을 수행하여 (입력보다 특성 맵의 크기가 작은)특성 맵을 만드는 경우는 **밸리드 패딩(valid padding)**이라고 부릅니다.\n",
        "\n",
        "합성곱에서 패딩을 주로 사용하는 이유는 원소들이 최대한 많은 횟수만큼 계산되도록 조치하기 위함입니다. 원소마다 계산되는 횟수에 차이가 생기면 덜 계산된 원소는 원소가 지닌 중요한 정보를 잃게 됩니다. 특히 주변에 위치한 원소는 계산 횟수가 적기 때문에 정보를 잃어버리기 쉽습니다. 따라서 합성곱 신경망에서 주로 사용하는 세임 패딩은 가장자리에 위치한 원소가 정보를 잃지 않도록 도움을 줍니다. 세임 패딩은 `Conv2D` 클래스의 `padding` 매개변수에 `'same'`으로 지정하면 사용할 수 있습니다. 디폴트는 `'valid'`로 밸리드 패딩을 의미합니다.\n",
        "\n",
        "물론 합성곱 연산을 두 칸씩 이동하도록 지정할 수도 있습니다. 도장이 이동하는 칸의 개수라고 생각하면 쉽습니다. 이동하는 칸수가 늘면 커널 도장을 찍는 횟수는 줄고 특성 맵의 크기도 작아집니다. 이 이동의 크기를 **스트라이드(stride)**라고 부르며 매개변수 `strides`에 숫자로 지정하여 조정할 수 있습니다. 디폴트는 `1`입니다. 대부분 디폴트 값을 사용하므로 조정하는 경우는 드뭅니다."
      ],
      "metadata": {
        "id": "Tu9IadVAs5TE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **풀링**"
      ],
      "metadata": {
        "id": "rejRcKeltUyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "작업 중\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BbLoXZkcysga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **합성곱 신경망의 전체 구조**"
      ],
      "metadata": {
        "id": "Yp-vPcdStUvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **컬러 이미지를 사용한 합성곱**"
      ],
      "metadata": {
        "id": "6Yd533IntUtE"
      }
    }
  ]
}